{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas \n",
    "import random \n",
    "import time\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv(\"ionosphere_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1  0  0.99539  -0.05889  0.85243  0.02306  0.83398  -0.37708      1.1  \\\n",
      "0  1  0  1.00000  -0.18829  0.93035 -0.36156 -0.10868  -0.93597  1.00000   \n",
      "1  1  0  1.00000  -0.03365  1.00000  0.00485  1.00000  -0.12062  0.88965   \n",
      "2  1  0  1.00000  -0.45161  1.00000  1.00000  0.71216  -1.00000  0.00000   \n",
      "3  1  0  1.00000  -0.02401  0.94140  0.06531  0.92106  -0.23255  0.77152   \n",
      "4  1  0  0.02337  -0.00592 -0.09924 -0.11949 -0.00763  -0.11824  0.14706   \n",
      "\n",
      "   0.03760  ...  -0.51171  0.41078  -0.46168  0.21266  -0.34090  0.42267  \\\n",
      "0 -0.04549  ...  -0.26569 -0.20468  -0.18401 -0.19040  -0.11593 -0.16626   \n",
      "1  0.01198  ...  -0.40220  0.58984  -0.22145  0.43100  -0.17365  0.60436   \n",
      "2  0.00000  ...   0.90695  0.51613   1.00000  1.00000  -0.20099  0.25682   \n",
      "3 -0.16399  ...  -0.65158  0.13290  -0.53206  0.02431  -0.62197 -0.05707   \n",
      "4  0.06637  ...  -0.01535 -0.03240   0.09223 -0.07859   0.00732  0.00000   \n",
      "\n",
      "   -0.54487  0.18641  -0.45300  g  \n",
      "0  -0.06288 -0.13738  -0.02447  b  \n",
      "1  -0.24180  0.56045  -0.38238  g  \n",
      "2   1.00000 -0.32382   1.00000  b  \n",
      "3  -0.59573 -0.04608  -0.65697  g  \n",
      "4   0.00000 -0.00039   0.12011  b  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                1      0     0.99539    -0.05889     0.85243     0.02306  \\\n",
      "count  350.000000  350.0  350.000000  350.000000  350.000000  350.000000   \n",
      "mean     0.891429    0.0    0.640330    0.044667    0.600350    0.116154   \n",
      "std      0.311546    0.0    0.498059    0.442032    0.520431    0.461443   \n",
      "min      0.000000    0.0   -1.000000   -1.000000   -1.000000   -1.000000   \n",
      "25%      1.000000    0.0    0.471518   -0.065388    0.412555   -0.024868   \n",
      "50%      1.000000    0.0    0.870795    0.016700    0.808620    0.021170   \n",
      "75%      1.000000    0.0    1.000000    0.194727    1.000000    0.335318   \n",
      "max      1.000000    0.0    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "          0.83398    -0.37708         1.1     0.03760  ...     0.56811  \\\n",
      "count  350.000000  350.000000  350.000000  350.000000  ...  350.000000   \n",
      "mean     0.549284    0.120779    0.510453    0.181756  ...    0.395643   \n",
      "std      0.493124    0.520816    0.507117    0.484482  ...    0.579206   \n",
      "min     -1.000000   -1.000000   -1.000000   -1.000000  ...   -1.000000   \n",
      "25%      0.209105   -0.053483    0.086785   -0.049003  ...    0.000000   \n",
      "50%      0.728000    0.015085    0.682430    0.017550  ...    0.549175   \n",
      "75%      0.970445    0.451572    0.950555    0.536192  ...    0.907165   \n",
      "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
      "\n",
      "         -0.51171     0.41078    -0.46168     0.21266    -0.34090     0.42267  \\\n",
      "count  350.000000  350.000000  350.000000  350.000000  350.000000  350.000000   \n",
      "mean    -0.069928    0.542015   -0.068417    0.378919   -0.027013    0.352313   \n",
      "std      0.508675    0.516896    0.550411    0.576642    0.508425    0.572289   \n",
      "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
      "25%     -0.323745    0.283612   -0.428992    0.000000   -0.234935    0.000000   \n",
      "50%     -0.014915    0.708530   -0.017685    0.499215    0.000000    0.446875   \n",
      "75%      0.157922    0.999972    0.154862    0.884572    0.154218    0.859490   \n",
      "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "         -0.54487     0.18641    -0.45300  \n",
      "count  350.000000  350.000000  350.000000  \n",
      "mean    -0.002248    0.349829    0.015816  \n",
      "std      0.513491    0.523339    0.468338  \n",
      "min     -1.000000   -1.000000   -1.000000  \n",
      "25%     -0.239347    0.000000   -0.161013  \n",
      "50%      0.000000    0.413115    0.000000  \n",
      "75%      0.200935    0.816777    0.172105  \n",
      "max      1.000000    1.000000    1.000000  \n",
      "\n",
      "[8 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (350, 35)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape:\", dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types: 1              int64\n",
      "0              int64\n",
      "0.99539      float64\n",
      "-0.05889     float64\n",
      "0.85243      float64\n",
      "0.02306      float64\n",
      "0.83398      float64\n",
      "-0.37708     float64\n",
      "1.1          float64\n",
      "0.03760      float64\n",
      "0.85243.1    float64\n",
      "-0.17755     float64\n",
      "0.59755      float64\n",
      "-0.44945     float64\n",
      "0.60536      float64\n",
      "-0.38223     float64\n",
      "0.84356      float64\n",
      "-0.38542     float64\n",
      "0.58212      float64\n",
      "-0.32192     float64\n",
      "0.56971      float64\n",
      "-0.29674     float64\n",
      "0.36946      float64\n",
      "-0.47357     float64\n",
      "0.56811      float64\n",
      "-0.51171     float64\n",
      "0.41078      float64\n",
      "-0.46168     float64\n",
      "0.21266      float64\n",
      "-0.34090     float64\n",
      "0.42267      float64\n",
      "-0.54487     float64\n",
      "0.18641      float64\n",
      "-0.45300     float64\n",
      "g             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Types:\", dataframe.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation:                   1   0   0.99539  -0.05889   0.85243   0.02306   0.83398  \\\n",
      "1          1.000000 NaN  0.301596 -0.006297  0.155750  0.127836  0.221436   \n",
      "0               NaN NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "0.99539    0.301596 NaN  1.000000  0.143957  0.476106  0.026199  0.439608   \n",
      "-0.05889  -0.006297 NaN  0.143957  1.000000  0.001477 -0.190469 -0.053673   \n",
      "0.85243    0.155750 NaN  0.476106  0.001477  1.000000  0.038617  0.596761   \n",
      "0.02306    0.127836 NaN  0.026199 -0.190469  0.038617  1.000000 -0.009900   \n",
      "0.83398    0.221436 NaN  0.439608 -0.053673  0.596761 -0.009900  1.000000   \n",
      "-0.37708   0.028071 NaN  0.010682  0.254716 -0.028520  0.274571 -0.149115   \n",
      "1.1        0.188565 NaN  0.470618 -0.302097  0.449869 -0.120323  0.461131   \n",
      "0.03760   -0.051602 NaN  0.048563  0.207541 -0.033840  0.199945 -0.089832   \n",
      "0.85243.1  0.033499 NaN  0.324097 -0.189778  0.449341 -0.291265  0.412233   \n",
      "-0.17755   0.072946 NaN  0.171587  0.315656  0.043871  0.163661 -0.019307   \n",
      "0.59755    0.102275 NaN  0.217141 -0.149037  0.481910 -0.307076  0.630929   \n",
      "-0.44945   0.200704 NaN  0.167196  0.236295  0.129002  0.134813  0.085657   \n",
      "0.60536    0.113269 NaN  0.197679 -0.252959  0.398549 -0.359214  0.615180   \n",
      "-0.38223   0.101621 NaN  0.096522  0.185484  0.089518  0.157399 -0.019897   \n",
      "0.84356    0.057094 NaN  0.220259 -0.250863  0.277211 -0.316545  0.378987   \n",
      "-0.38542   0.076863 NaN  0.173841 -0.148103  0.028687  0.187799  0.117351   \n",
      "0.58212    0.199954 NaN  0.284813 -0.332061  0.221154 -0.208415  0.372229   \n",
      "-0.32192   0.019815 NaN  0.152152  0.166951  0.042789 -0.061625  0.160016   \n",
      "0.56971    0.173514 NaN  0.148734 -0.280908  0.325871 -0.114776  0.586398   \n",
      "-0.29674  -0.153418 NaN  0.139435 -0.035816  0.164615 -0.132836  0.191963   \n",
      "0.36946    0.011763 NaN  0.250990 -0.143723  0.503031 -0.215783  0.373345   \n",
      "-0.47357  -0.081887 NaN -0.010979  0.163826  0.099490 -0.287270  0.114176   \n",
      "0.56811    0.016426 NaN  0.304551 -0.104454  0.242763 -0.177437  0.286431   \n",
      "-0.51171   0.150841 NaN -0.071565 -0.237842 -0.031098  0.041334  0.089303   \n",
      "0.41078   -0.202901 NaN  0.078492 -0.047087  0.141311 -0.175606  0.098040   \n",
      "-0.46168  -0.010023 NaN  0.124980  0.000265  0.185702 -0.069241  0.110702   \n",
      "0.21266    0.133958 NaN  0.345337 -0.041292  0.258162 -0.029563  0.301286   \n",
      "-0.34090  -0.120887 NaN  0.059221  0.342101  0.051967 -0.158541 -0.014155   \n",
      "0.42267    0.166942 NaN  0.246587 -0.172211  0.399813 -0.100177  0.415220   \n",
      "-0.54487  -0.100040 NaN -0.007202 -0.123701  0.027193  0.316716 -0.006597   \n",
      "0.18641    0.163324 NaN  0.264207 -0.154207  0.384081  0.016722  0.546732   \n",
      "-0.45300   0.011802 NaN  0.002624  0.033991 -0.098269  0.184914 -0.074955   \n",
      "\n",
      "           -0.37708       1.1   0.03760  ...   0.56811  -0.51171   0.41078  \\\n",
      "1          0.028071  0.188565 -0.051602  ...  0.016426  0.150841 -0.202901   \n",
      "0               NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
      "0.99539    0.010682  0.470618  0.048563  ...  0.304551 -0.071565  0.078492   \n",
      "-0.05889   0.254716 -0.302097  0.207541  ... -0.104454 -0.237842 -0.047087   \n",
      "0.85243   -0.028520  0.449869 -0.033840  ...  0.242763 -0.031098  0.141311   \n",
      "0.02306    0.274571 -0.120323  0.199945  ... -0.177437  0.041334 -0.175606   \n",
      "0.83398   -0.149115  0.461131 -0.089832  ...  0.286431  0.089303  0.098040   \n",
      "-0.37708   1.000000 -0.334263  0.373289  ... -0.179372 -0.135712 -0.255178   \n",
      "1.1       -0.334263  1.000000 -0.251496  ...  0.356262  0.110133  0.173156   \n",
      "0.03760    0.373289 -0.251496  1.000000  ... -0.254596 -0.044471 -0.251218   \n",
      "0.85243.1 -0.362883  0.670289 -0.337064  ...  0.365532  0.133735  0.292981   \n",
      "-0.17755   0.428144 -0.166179  0.441274  ... -0.232977 -0.078632 -0.228548   \n",
      "0.59755   -0.355525  0.562027 -0.406199  ...  0.364474  0.198292  0.290393   \n",
      "-0.44945   0.251505 -0.086225  0.323478  ... -0.208812  0.068031 -0.314966   \n",
      "0.60536   -0.351662  0.618321 -0.374700  ...  0.456634  0.230080  0.339916   \n",
      "-0.38223   0.418101 -0.030043  0.333803  ... -0.264928  0.177877 -0.314489   \n",
      "0.84356   -0.490854  0.632860 -0.391774  ...  0.553947  0.131646  0.428187   \n",
      "-0.38542   0.066761  0.203348  0.130225  ... -0.175173  0.413982 -0.200545   \n",
      "0.58212   -0.400145  0.673526 -0.471507  ...  0.549703  0.174619  0.425066   \n",
      "-0.32192   0.076191  0.069021 -0.001907  ... -0.199907  0.396618 -0.166456   \n",
      "0.56971   -0.369989  0.492114 -0.404628  ...  0.553564  0.161383  0.399349   \n",
      "-0.29674  -0.214000  0.239383 -0.040941  ... -0.078261  0.395503 -0.031727   \n",
      "0.36946   -0.270946  0.352655 -0.318493  ...  0.533641  0.051886  0.569237   \n",
      "-0.47357   0.004901  0.163798  0.101281  ... -0.079517  0.351605 -0.037292   \n",
      "0.56811   -0.179372  0.356262 -0.254596  ...  1.000000 -0.076360  0.503852   \n",
      "-0.51171  -0.135712  0.110133 -0.044471  ... -0.076360  1.000000 -0.011957   \n",
      "0.41078   -0.255178  0.173156 -0.251218  ...  0.503852 -0.011957  1.000000   \n",
      "-0.46168   0.070569  0.149090  0.071472  ...  0.177016  0.431435  0.057783   \n",
      "0.21266   -0.140711  0.331087 -0.123571  ...  0.651313 -0.114350  0.508968   \n",
      "-0.34090   0.077044 -0.030340 -0.009109  ...  0.014174  0.279999  0.163069   \n",
      "0.42267   -0.166568  0.316109 -0.155580  ...  0.516093 -0.162581  0.376532   \n",
      "-0.54487   0.149936 -0.064782 -0.016565  ...  0.135608  0.338980  0.159822   \n",
      "0.18641   -0.202003  0.346182 -0.203949  ...  0.461080 -0.086845  0.469208   \n",
      "-0.45300   0.358863 -0.093100  0.097406  ...  0.112110  0.219702  0.082369   \n",
      "\n",
      "           -0.46168   0.21266  -0.34090   0.42267  -0.54487   0.18641  \\\n",
      "1         -0.010023  0.133958 -0.120887  0.166942 -0.100040  0.163324   \n",
      "0               NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "0.99539    0.124980  0.345337  0.059221  0.246587 -0.007202  0.264207   \n",
      "-0.05889   0.000265 -0.041292  0.342101 -0.172211 -0.123701 -0.154207   \n",
      "0.85243    0.185702  0.258162  0.051967  0.399813  0.027193  0.384081   \n",
      "0.02306   -0.069241 -0.029563 -0.158541 -0.100177  0.316716  0.016722   \n",
      "0.83398    0.110702  0.301286 -0.014155  0.415220 -0.006597  0.546732   \n",
      "-0.37708   0.070569 -0.140711  0.077044 -0.166568  0.149936 -0.202003   \n",
      "1.1        0.149090  0.331087 -0.030340  0.316109 -0.064782  0.346182   \n",
      "0.03760    0.071472 -0.123571 -0.009109 -0.155580 -0.016565 -0.203949   \n",
      "0.85243.1  0.199005  0.397703  0.075868  0.294606  0.025995  0.340368   \n",
      "-0.17755   0.060001 -0.209008  0.137819 -0.208759  0.008265 -0.181910   \n",
      "0.59755    0.147574  0.278329  0.095023  0.355420 -0.040745  0.474196   \n",
      "-0.44945   0.064883 -0.216354  0.093954 -0.147821 -0.071338 -0.097253   \n",
      "0.60536    0.165153  0.356371  0.090786  0.445146 -0.011946  0.491417   \n",
      "-0.38223   0.217864 -0.160700  0.144587 -0.183492  0.098710 -0.181069   \n",
      "0.84356    0.170293  0.405264  0.076025  0.358724  0.018186  0.361045   \n",
      "-0.38542   0.288756 -0.118796  0.066447 -0.157963  0.255272 -0.059822   \n",
      "0.58212    0.206587  0.473622  0.086270  0.418540  0.126010  0.446554   \n",
      "-0.32192   0.271390 -0.213657  0.396170 -0.304998  0.123897 -0.108395   \n",
      "0.56971    0.074263  0.480092  0.072321  0.511262  0.123298  0.617176   \n",
      "-0.29674   0.406388 -0.087153  0.323009 -0.075546  0.206372 -0.091000   \n",
      "0.36946    0.207876  0.540516  0.166001  0.538981  0.160822  0.503507   \n",
      "-0.47357   0.375949 -0.168758  0.363756 -0.127661  0.082113 -0.212521   \n",
      "0.56811    0.177016  0.651313  0.014174  0.516093  0.135608  0.461080   \n",
      "-0.51171   0.431435 -0.114350  0.279999 -0.162581  0.338980 -0.086845   \n",
      "0.41078    0.057783  0.508968  0.163069  0.376532  0.159822  0.469208   \n",
      "-0.46168   1.000000  0.041449  0.384705 -0.007891  0.499808 -0.125572   \n",
      "0.21266    0.041449  1.000000 -0.011516  0.554034  0.055223  0.579576   \n",
      "-0.34090   0.384705 -0.011516  1.000000 -0.163462  0.295856 -0.181240   \n",
      "0.42267   -0.007891  0.554034 -0.163462  1.000000 -0.028553  0.692629   \n",
      "-0.54487   0.499808  0.055223  0.295856 -0.028553  1.000000 -0.013964   \n",
      "0.18641   -0.125572  0.579576 -0.181240  0.692629 -0.013964  1.000000   \n",
      "-0.45300   0.375542  0.081807  0.390278 -0.037282  0.513529 -0.132940   \n",
      "\n",
      "           -0.45300  \n",
      "1          0.011802  \n",
      "0               NaN  \n",
      "0.99539    0.002624  \n",
      "-0.05889   0.033991  \n",
      "0.85243   -0.098269  \n",
      "0.02306    0.184914  \n",
      "0.83398   -0.074955  \n",
      "-0.37708   0.358863  \n",
      "1.1       -0.093100  \n",
      "0.03760    0.097406  \n",
      "0.85243.1 -0.150627  \n",
      "-0.17755   0.064796  \n",
      "0.59755   -0.064328  \n",
      "-0.44945   0.093601  \n",
      "0.60536   -0.118982  \n",
      "-0.38223   0.239550  \n",
      "0.84356   -0.061430  \n",
      "-0.38542   0.052033  \n",
      "0.58212    0.002479  \n",
      "-0.32192   0.187655  \n",
      "0.56971   -0.001505  \n",
      "-0.29674   0.131417  \n",
      "0.36946    0.049387  \n",
      "-0.47357   0.092643  \n",
      "0.56811    0.112110  \n",
      "-0.51171   0.219702  \n",
      "0.41078    0.082369  \n",
      "-0.46168   0.375542  \n",
      "0.21266    0.081807  \n",
      "-0.34090   0.390278  \n",
      "0.42267   -0.037282  \n",
      "-0.54487   0.513529  \n",
      "0.18641   -0.132940  \n",
      "-0.45300   1.000000  \n",
      "\n",
      "[34 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Correlation:\", dataframe.corr(method='pearson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1.0 ... -0.13738 -0.02447 'b']\n",
      " [1 0 1.0 ... 0.56045 -0.38238 'g']\n",
      " [1 0 1.0 ... -0.32382 1.0 'b']\n",
      " ...\n",
      " [1 0 0.94701 ... 0.9269700000000001 -0.00577 'g']\n",
      " [1 0 0.9060799999999999 ... 0.87403 -0.16243 'g']\n",
      " [1 0 0.8471 ... 0.85764 -0.06151 'g']]\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1.0, ..., 0.18353, -0.46603, 'g'],\n",
       "       [1, 0, 0.7629600000000001, ..., 1.0, -0.5703699999999999, 'g'],\n",
       "       [1, 0, 0.9800200000000001, ..., 0.9724700000000001, 0.08616, 'g'],\n",
       "       ...,\n",
       "       [1, 0, 0.25316, ..., 0.0, 0.0, 'b'],\n",
       "       [1, 0, 0.9176700000000001, ..., -0.64056, 0.053939999999999995,\n",
       "        'g'],\n",
       "       [1, 0, 1.0, ..., 0.82895, 0.07895, 'b']], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shuffle\n",
    "dataset = np.array(dataframe.values)\n",
    "dataset_shuf = []\n",
    "index_shuf = list(range(len(dataset)))\n",
    "random.shuffle(index_shuf)\n",
    "for i in index_shuf:\n",
    "    dataset_shuf.append(dataset[i,:])   \n",
    "dataset_shuf = np.array(dataset_shuf)\n",
    "dataset_shuf.reshape(350,35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1.0 ... 0.18353 -0.46603 0]\n",
      " [1 0 0.7629600000000001 ... 1.0 -0.5703699999999999 0]\n",
      " [1 0 0.9800200000000001 ... 0.9724700000000001 0.08616 0]\n",
      " ...\n",
      " [1 0 0.25316 ... 0.0 0.0 1]\n",
      " [1 0 0.9176700000000001 ... -0.64056 0.053939999999999995 0]\n",
      " [1 0 1.0 ... 0.82895 0.07895 1]]\n"
     ]
    }
   ],
   "source": [
    "#ont hot g = 0 b = 1\n",
    "for i in range(350) :\n",
    "    if dataset_shuf[i,34] == 'g' :\n",
    "        dataset_shuf[i,34] = 0\n",
    "    elif dataset_shuf[i,34] == 'b' :\n",
    "        dataset_shuf[i,34] = 1\n",
    "print(dataset_shuf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = dataset_shuf[:270,0:34]\n",
    "Y_train = dataset_shuf[:270,34:35]\n",
    "X_train.reshape(270,34)\n",
    "Y_train.reshape(270,1)\n",
    "\n",
    "X_test = dataset_shuf[270:,0:34]\n",
    "Y_test = dataset_shuf[270:,34:35]\n",
    "X_test.reshape(80,34)\n",
    "Y_test.reshape(80,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    1\n",
       "8    0\n",
       "9    1\n",
       "10   0\n",
       "11   0\n",
       "12   0\n",
       "13   0\n",
       "14   0\n",
       "15   1\n",
       "16   1\n",
       "17   1\n",
       "18   0\n",
       "19   0\n",
       "20   0\n",
       "21   0\n",
       "22   0\n",
       "23   0\n",
       "24   1\n",
       "25   1\n",
       "26   0\n",
       "27   0\n",
       "28   0\n",
       "29   1\n",
       "..  ..\n",
       "240  1\n",
       "241  0\n",
       "242  1\n",
       "243  0\n",
       "244  0\n",
       "245  0\n",
       "246  1\n",
       "247  0\n",
       "248  1\n",
       "249  0\n",
       "250  0\n",
       "251  0\n",
       "252  0\n",
       "253  0\n",
       "254  0\n",
       "255  1\n",
       "256  0\n",
       "257  0\n",
       "258  1\n",
       "259  0\n",
       "260  1\n",
       "261  1\n",
       "262  1\n",
       "263  0\n",
       "264  0\n",
       "265  0\n",
       "266  0\n",
       "267  0\n",
       "268  0\n",
       "269  0\n",
       "\n",
       "[270 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define weight:\n",
    "\n",
    "#16 for hidden layer1\n",
    "#64 for hidden layer2\n",
    "#64 for hidden layer3\n",
    "#64 for hidden layer4\n",
    "#64 for hidden layer5\n",
    "#8 for output layer6\n",
    "\n",
    "weight_hidden = np.random.random((34,64))-0.5\n",
    "weight_hidden2 = np.random.random((64,64))-0.5\n",
    "weight_hidden3 = np.random.random((64,64))-0.5\n",
    "weight_hidden4 = np.random.random((64,64))-0.5\n",
    "weight_hidden5 = np.random.random((64,8))-0.5\n",
    "weight_output = np.random.random((8,1))-0.5\n",
    "lr = 0.003\n",
    "\n",
    "bias = 0.01\n",
    "bias1 = 0.01\n",
    "bias2 = 0.01\n",
    "bias3 = 0.01\n",
    "bias4 = 0.01\n",
    "bias5 = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x) :\n",
    "    return x * (x > 0) + 0.01 * x * (x <= 0)\n",
    "\n",
    "def ReLU_der(x) :\n",
    "    return 1 * (x > 0) + 0.01 * (x <= 0)\n",
    "    \n",
    "def Sigmoid(x) :\n",
    "    x = x.astype('float64')\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def Sigmoid_der(x) :\n",
    "    x = x.astype('float64')\n",
    "    return Sigmoid(x) * (1 - Sigmoid(x))\n",
    "\n",
    "def limit(x) :  \n",
    "    while(np.max(x) > 0.1 or np.min(x) < -0.1) : \n",
    "            x /= 10\n",
    "    return x \n",
    "def error(x, y) :\n",
    "    CEE = 0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 0 :\n",
    "            CEE += -math.log(1-x[i])\n",
    "        elif y[i] == 1:    \n",
    "            CEE += -math.log(x[i])\n",
    "    return CEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now training  0.0 %\n",
      "156.07530557978208\n",
      "now training  2.0 %\n",
      "30.1676999644101\n",
      "now training  4.0 %\n",
      "20.093421758428306\n",
      "now training  6.0 %\n",
      "14.53710981820543\n",
      "now training  8.0 %\n",
      "13.406619916200793\n",
      "now training  10.0 %\n",
      "10.29253437036917\n",
      "now training  12.0 %\n",
      "9.21778310994552\n",
      "now training  14.0 %\n",
      "8.3232174040583\n",
      "now training  16.0 %\n",
      "7.316367140792451\n",
      "now training  18.0 %\n",
      "6.537754867483604\n",
      "now training  20.0 %\n",
      "6.996498036765264\n",
      "now training  22.0 %\n",
      "5.6718990872635855\n",
      "now training  24.0 %\n",
      "5.154995931969171\n",
      "now training  26.0 %\n",
      "4.759611197000178\n",
      "now training  28.0 %\n",
      "4.375697471943204\n",
      "now training  30.0 %\n",
      "4.9678353347630635\n",
      "now training  32.0 %\n",
      "3.8755678087912657\n",
      "now training  34.0 %\n",
      "3.868194196614918\n",
      "now training  36.0 %\n",
      "3.462909419457896\n",
      "now training  38.0 %\n",
      "3.3923305320952446\n",
      "now training  40.0 %\n",
      "3.56977578461343\n",
      "now training  42.0 %\n",
      "3.045295990388714\n",
      "now training  44.0 %\n",
      "3.0219923823933383\n",
      "now training  46.0 %\n",
      "3.004205917557786\n",
      "now training  48.0 %\n",
      "2.715906457102839\n",
      "now training  50.0 %\n",
      "2.626910282018436\n",
      "now training  52.0 %\n",
      "2.5601684183764033\n",
      "now training  54.0 %\n",
      "2.6777516209631544\n",
      "now training  56.0 %\n",
      "2.6185126288657252\n",
      "now training  58.0 %\n",
      "2.34624148969182\n",
      "now training  60.0 %\n",
      "2.2885316748848488\n",
      "now training  62.0 %\n",
      "2.3070372186233308\n",
      "now training  64.0 %\n",
      "2.3359434793078937\n",
      "now training  66.0 %\n",
      "2.2489808614239895\n",
      "now training  68.0 %\n",
      "2.083349423733708\n",
      "now training  70.0 %\n",
      "2.0992156332019256\n",
      "now training  72.0 %\n",
      "2.0645462884727226\n",
      "now training  74.0 %\n",
      "1.9873866346859514\n",
      "now training  76.0 %\n",
      "1.9895647119741573\n",
      "now training  78.0 %\n",
      "1.9856704278353074\n",
      "now training  80.0 %\n",
      "2.034707249841031\n",
      "now training  82.0 %\n",
      "1.9521907691898603\n",
      "now training  84.0 %\n",
      "1.8946391912606986\n",
      "now training  86.0 %\n",
      "1.9458068975003644\n",
      "now training  88.0 %\n",
      "1.8496576200715493\n",
      "now training  90.0 %\n",
      "1.8205780364154676\n",
      "now training  92.0 %\n",
      "1.8052202779290636\n",
      "now training  94.0 %\n",
      "1.8119804409356843\n",
      "now training  96.0 %\n",
      "1.862810157248266\n",
      "now training  98.0 %\n",
      "1.7621357983286687\n"
     ]
    }
   ],
   "source": [
    "epochtimes = 10000\n",
    "mini_batch = 16\n",
    "bestloss1 = 1e30 #Mini Batch Loss\n",
    "preloss = 1e30   #decay the learning rate\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(epochtimes):\n",
    "    X_train_random = []\n",
    "    Y_train_random = []\n",
    "    for i in range(mini_batch):\n",
    "        rindex = random.randint(0,len(X_train)-1)\n",
    "        X_train_random.append(X_train[rindex,:])\n",
    "        Y_train_random.append(Y_train[rindex,:])\n",
    "    X_train_random = np.array(X_train_random)\n",
    "    Y_train_random = np.array(Y_train_random)\n",
    "    \n",
    "   \n",
    "        \n",
    "    input_hidden = np.dot(X_train_random, weight_hidden) + bias\n",
    "    output_hidden = ReLU(input_hidden)\n",
    "    \n",
    "    input_hidden2 = np.dot(output_hidden, weight_hidden2) + bias1\n",
    "    output_hidden2 = ReLU(input_hidden2)\n",
    "    input_hidden3 = np.dot(output_hidden2, weight_hidden3) + bias2\n",
    "    output_hidden3 = ReLU(input_hidden3)\n",
    "    input_hidden4 = np.dot(output_hidden3, weight_hidden4) + bias3\n",
    "    output_hidden4 = ReLU(input_hidden4)\n",
    "    input_hidden5 = np.dot(output_hidden4, weight_hidden5) + bias4\n",
    "    output_hidden5 = ReLU(input_hidden5)\n",
    "    input_op = np.dot(output_hidden5, weight_output)+ bias5\n",
    "    output_op = Sigmoid(input_op)\n",
    "   \n",
    "    \n",
    "    #==========================================\n",
    "    \n",
    "    derror_douto = output_op - Y_train_random\n",
    "    douto_dino = Sigmoid_der(input_op)\n",
    "    dino_dwo = output_hidden5      \n",
    "    derror_dwo = np.dot(dino_dwo.T, derror_douto * douto_dino)\n",
    "    derror_dbias5 = derror_douto * douto_dino\n",
    "    \n",
    "    #==========================================\n",
    "    \n",
    "    derror_dino = derror_douto * douto_dino\n",
    "    dino_douth5 = weight_output\n",
    "    derror_douth5 = np.dot(derror_dino, dino_douth5.T)\n",
    "    douth5_dinh5 = ReLU_der(input_hidden5)\n",
    "    dinh5_dwh5 = output_hidden4\n",
    "    derror_dwh5 = np.dot(dinh5_dwh5.T, douth5_dinh5 * derror_douth5)\n",
    "    derror_dbias4 = douth5_dinh5 * derror_douth5\n",
    "      \n",
    "    #==========================================\n",
    "    \n",
    "    derror_dinh5 = derror_douth5 * douth5_dinh5\n",
    "    dinh5_douth4 = weight_hidden5\n",
    "    derror_douth4 = np.dot(derror_dinh5, dinh5_douth4.T)\n",
    "    douth4_dinh4 = ReLU_der(input_hidden4)\n",
    "    dinh4_dwh4 = output_hidden3\n",
    "    derror_dwh4 = np.dot(dinh4_dwh4.T, douth4_dinh4 * derror_douth4)\n",
    "    derror_dbias3 = douth4_dinh4 * derror_douth4\n",
    "        \n",
    "    #==========================================\n",
    "    \n",
    "    derror_dinh4 = derror_douth4 * douth4_dinh4\n",
    "    dinh4_douth3 = weight_hidden4\n",
    "    derror_douth3 = np.dot(derror_dinh4, dinh4_douth3.T)\n",
    "    douth3_dinh3 = ReLU_der(input_hidden3)\n",
    "    dinh3_dwh3 = output_hidden2\n",
    "    derror_dwh3 = np.dot(dinh3_dwh3.T, douth3_dinh3 * derror_douth3)\n",
    "    derror_dbias2 = douth3_dinh3 * derror_douth3\n",
    "        \n",
    "    #==========================================\n",
    "    \n",
    "    derror_dinh3 = derror_douth3 * douth3_dinh3\n",
    "    dinh3_douth2 = weight_hidden3\n",
    "    derror_douth2 = np.dot(derror_dinh3, dinh3_douth2.T)\n",
    "    douth2_dinh2 = ReLU_der(input_hidden2)\n",
    "    dinh2_dwh2 = output_hidden\n",
    "    derror_dwh2 = np.dot(dinh2_dwh2.T, douth2_dinh2 * derror_douth2)\n",
    "    derror_dbias1 = douth2_dinh2 * derror_douth2\n",
    "        \n",
    "    #==========================================\n",
    "    \n",
    "    derror_dinh2 = derror_douth2 * douth2_dinh2\n",
    "    dinh2_douth = weight_hidden2\n",
    "    derror_douth = np.dot(derror_dinh2, dinh2_douth.T)\n",
    "    douth_dinh = ReLU_der(input_hidden)\n",
    "    dinh_dwh = X_train_random\n",
    "    derror_dwh = np.dot(dinh_dwh.T, douth_dinh * derror_douth)    \n",
    "    derror_dbias = douth_dinh * derror_douth\n",
    "    \n",
    "    #==========================================\n",
    "       \n",
    "    \n",
    "    \n",
    "    weight_hidden = weight_hidden-lr * derror_dwh\n",
    "    weight_hidden2 = weight_hidden2-lr * derror_dwh2\n",
    "    weight_hidden3 = weight_hidden3-lr * derror_dwh3\n",
    "    weight_hidden4 = weight_hidden4-lr * derror_dwh4\n",
    "    weight_hidden5 = weight_hidden5-lr * derror_dwh5\n",
    "    weight_output = weight_output-lr * derror_dwo\n",
    "    \n",
    "    bias -= lr * derror_dbias.sum()/np.size(derror_dbias)\n",
    "    bias1 -= lr * derror_dbias1.sum()/np.size(derror_dbias1)\n",
    "    bias2 -= lr * derror_dbias2.sum()/np.size(derror_dbias2)\n",
    "    bias3 -= lr * derror_dbias3.sum()/np.size(derror_dbias3)\n",
    "    bias4 -= lr * derror_dbias4.sum()/np.size(derror_dbias4)\n",
    "    bias5 -= lr * derror_dbias5.sum()/np.size(derror_dbias5)\n",
    "           \n",
    "        \n",
    "    #calulate error \n",
    "    if epoch % 200 == 0 : \n",
    "        input_hidden = np.dot(X_train, weight_hidden) + bias\n",
    "        output_hidden = ReLU(input_hidden)\n",
    "        input_hidden2 = np.dot(output_hidden, weight_hidden2) + bias1\n",
    "        output_hidden2 = ReLU(input_hidden2)\n",
    "        input_hidden3 = np.dot(output_hidden2, weight_hidden3) + bias2\n",
    "        output_hidden3 = ReLU(input_hidden3)\n",
    "        input_hidden4 = np.dot(output_hidden3, weight_hidden4) + bias3\n",
    "        output_hidden4 = ReLU(input_hidden4)\n",
    "        input_hidden5 = np.dot(output_hidden4, weight_hidden5) + bias4\n",
    "        output_hidden5 = ReLU(input_hidden5)\n",
    "        input_op = np.dot(output_hidden5, weight_output)+ bias5\n",
    "        output_op = Sigmoid(input_op)\n",
    "        error_out = error(output_op, Y_train)\n",
    "        \n",
    "   \n",
    "        #set decay for learning rate\n",
    "        if error_out > preloss :\n",
    "            lr *= 0.9\n",
    "            \n",
    "        preloss = error_out\n",
    "       \n",
    "        \n",
    "        print('now training ',epoch*100/epochtimes,'%')\n",
    "        print(error_out)\n",
    "        #print(error_out)\n",
    "        #print('\\n',lr * derror_dwh,'\\n', lr * derror_dwo,'\\n')\n",
    "        \n",
    "       \n",
    "        #print(derror_wh, derror_wo)\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define weight:\n",
    "\n",
    "#16 for hidden layer1\n",
    "#64 for hidden layer2\n",
    "#64 for hidden layer3\n",
    "#64 for hidden layer4\n",
    "#64 for hidden layer5\n",
    "#8 for output layer6\n",
    "\n",
    "weight_hidden = np.random.random((34,64))-0.5\n",
    "weight_hidden2 = np.random.random((64,64))-0.5\n",
    "weight_hidden3 = np.random.random((64,64))-0.5\n",
    "weight_hidden4 = np.random.random((64,64))-0.5\n",
    "weight_hidden5 = np.random.random((64,8))-0.5\n",
    "weight_output = np.random.random((8,1))-0.5\n",
    "lr = 0.003\n",
    "\n",
    "bias = 0.01\n",
    "bias1 = 0.01\n",
    "bias2 = 0.01\n",
    "bias3 = 0.01\n",
    "bias4 = 0.01\n",
    "bias5 = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochtimes = 10000\n",
    "mini_batch = 16\n",
    "bestloss1 = 1e30 #Mini Batch Loss\n",
    "preloss = 1e30   #decay the learning rate\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(epochtimes):\n",
    "    X_train_random = []\n",
    "    Y_train_random = []\n",
    "    for i in range(mini_batch):\n",
    "        rindex = random.randint(0,len(X_train)-1)\n",
    "        X_train_random.append(X_train[rindex,:])\n",
    "        Y_train_random.append(Y_train[rindex,:])\n",
    "    X_train_random = np.array(X_train_random)\n",
    "    Y_train_random = np.array(Y_train_random)\n",
    "    \n",
    "   \n",
    "        \n",
    "    input_hidden = np.dot(X_train_random, weight_hidden) + bias\n",
    "    output_hidden = ReLU(input_hidden)\n",
    "    \n",
    "    input_hidden2 = np.dot(output_hidden, weight_hidden2) + bias1\n",
    "    output_hidden2 = ReLU(input_hidden2)\n",
    "    input_hidden3 = np.dot(output_hidden2, weight_hidden3) + bias2\n",
    "    output_hidden3 = ReLU(input_hidden3)\n",
    "    input_hidden4 = np.dot(output_hidden3, weight_hidden4) + bias3\n",
    "    output_hidden4 = ReLU(input_hidden4)\n",
    "    input_hidden5 = np.dot(output_hidden4, weight_hidden5) + bias4\n",
    "    output_hidden5 = ReLU(input_hidden5)\n",
    "    input_op = np.dot(output_hidden5, weight_output)+ bias5\n",
    "    output_op = Sigmoid(input_op)\n",
    "   \n",
    "    \n",
    "    #==========================================\n",
    "    \n",
    "    derror_douto = output_op - Y_train_random\n",
    "    douto_dino = Sigmoid_der(input_op)\n",
    "    dino_dwo = output_hidden5      \n",
    "    derror_dwo = np.dot(dino_dwo.T, derror_douto * douto_dino)\n",
    "    derror_dbias5 = derror_douto * douto_dino\n",
    "    \n",
    "    #==========================================\n",
    "    \n",
    "    derror_dino = derror_douto * douto_dino\n",
    "    dino_douth5 = weight_output\n",
    "    derror_douth5 = np.dot(derror_dino, dino_douth5.T)\n",
    "    douth5_dinh5 = ReLU_der(input_hidden5)\n",
    "    dinh5_dwh5 = output_hidden4\n",
    "    derror_dwh5 = np.dot(dinh5_dwh5.T, douth5_dinh5 * derror_douth5)\n",
    "    derror_dbias4 = douth5_dinh5 * derror_douth5\n",
    "      \n",
    "    #==========================================\n",
    "    \n",
    "    derror_dinh5 = derror_douth5 * douth5_dinh5\n",
    "    dinh5_douth4 = weight_hidden5\n",
    "    derror_douth4 = np.dot(derror_dinh5, dinh5_douth4.T)\n",
    "    douth4_dinh4 = ReLU_der(input_hidden4)\n",
    "    dinh4_dwh4 = output_hidden3\n",
    "    derror_dwh4 = np.dot(dinh4_dwh4.T, douth4_dinh4 * derror_douth4)\n",
    "    derror_dbias3 = douth4_dinh4 * derror_douth4\n",
    "        \n",
    "    #==========================================\n",
    "    \n",
    "    derror_dinh4 = derror_douth4 * douth4_dinh4\n",
    "    dinh4_douth3 = weight_hidden4\n",
    "    derror_douth3 = np.dot(derror_dinh4, dinh4_douth3.T)\n",
    "    douth3_dinh3 = ReLU_der(input_hidden3)\n",
    "    dinh3_dwh3 = output_hidden2\n",
    "    derror_dwh3 = np.dot(dinh3_dwh3.T, douth3_dinh3 * derror_douth3)\n",
    "    derror_dbias2 = douth3_dinh3 * derror_douth3\n",
    "        \n",
    "    #==========================================\n",
    "    \n",
    "    derror_dinh3 = derror_douth3 * douth3_dinh3\n",
    "    dinh3_douth2 = weight_hidden3\n",
    "    derror_douth2 = np.dot(derror_dinh3, dinh3_douth2.T)\n",
    "    douth2_dinh2 = ReLU_der(input_hidden2)\n",
    "    dinh2_dwh2 = output_hidden\n",
    "    derror_dwh2 = np.dot(dinh2_dwh2.T, douth2_dinh2 * derror_douth2)\n",
    "    derror_dbias1 = douth2_dinh2 * derror_douth2\n",
    "        \n",
    "    #==========================================\n",
    "    \n",
    "    derror_dinh2 = derror_douth2 * douth2_dinh2\n",
    "    dinh2_douth = weight_hidden2\n",
    "    derror_douth = np.dot(derror_dinh2, dinh2_douth.T)\n",
    "    douth_dinh = ReLU_der(input_hidden)\n",
    "    dinh_dwh = X_train_random\n",
    "    derror_dwh = np.dot(dinh_dwh.T, douth_dinh * derror_douth)    \n",
    "    derror_dbias = douth_dinh * derror_douth\n",
    "    \n",
    "    #==========================================\n",
    "       \n",
    "    \n",
    "    \n",
    "    weight_hidden = weight_hidden-lr * derror_dwh\n",
    "    weight_hidden2 = weight_hidden2-lr * derror_dwh2\n",
    "    weight_hidden3 = weight_hidden3-lr * derror_dwh3\n",
    "    weight_hidden4 = weight_hidden4-lr * derror_dwh4\n",
    "    weight_hidden5 = weight_hidden5-lr * derror_dwh5\n",
    "    weight_output = weight_output-lr * derror_dwo\n",
    "    \n",
    "    bias -= lr * derror_dbias.sum()/np.size(derror_dbias)\n",
    "    bias1 -= lr * derror_dbias1.sum()/np.size(derror_dbias1)\n",
    "    bias2 -= lr * derror_dbias2.sum()/np.size(derror_dbias2)\n",
    "    bias3 -= lr * derror_dbias3.sum()/np.size(derror_dbias3)\n",
    "    bias4 -= lr * derror_dbias4.sum()/np.size(derror_dbias4)\n",
    "    bias5 -= lr * derror_dbias5.sum()/np.size(derror_dbias5)\n",
    "           \n",
    "        \n",
    "    #calulate error \n",
    "    if epoch % 200 == 0 : \n",
    "        input_hidden = np.dot(X_train, weight_hidden) + bias\n",
    "        output_hidden = ReLU(input_hidden)\n",
    "        input_hidden2 = np.dot(output_hidden, weight_hidden2) + bias1\n",
    "        output_hidden2 = ReLU(input_hidden2)\n",
    "        input_hidden3 = np.dot(output_hidden2, weight_hidden3) + bias2\n",
    "        output_hidden3 = ReLU(input_hidden3)\n",
    "        input_hidden4 = np.dot(output_hidden3, weight_hidden4) + bias3\n",
    "        output_hidden4 = ReLU(input_hidden4)\n",
    "        input_hidden5 = np.dot(output_hidden4, weight_hidden5) + bias4\n",
    "        output_hidden5 = ReLU(input_hidden5)\n",
    "        input_op = np.dot(output_hidden5, weight_output)+ bias5\n",
    "        output_op = Sigmoid(input_op)\n",
    "        error_out = error(output_op, Y_train)\n",
    "        \n",
    "   \n",
    "        #set decay for learning rate\n",
    "        if error_out > preloss :\n",
    "            lr *= 0.9\n",
    "            \n",
    "        preloss = error_out\n",
    "       \n",
    "        \n",
    "        print('now training ',epoch*100/epochtimes,'%')\n",
    "        print(error_out)\n",
    "        #print(error_out)\n",
    "        #print('\\n',lr * derror_dwh,'\\n', lr * derror_dwo,'\\n')\n",
    "        \n",
    "       \n",
    "        #print(derror_wh, derror_wo)\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"bias:\",bias )\n",
    "print(\"bias1:\",bias1 )\n",
    "print(\"bias2:\",bias2 )\n",
    "print(\"bias3:\",bias3 )\n",
    "print(\"bias4:\",bias4 )\n",
    "print(\"bias5:\",bias5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_point = np.array(X_test)\n",
    "result1 = np.dot(single_point, weight_hidden)\n",
    "result2 = ReLU(result1)\n",
    "result3 = np.dot(result2, weight_hidden2)\n",
    "result4 = ReLU(result3)\n",
    "result5 = np.dot(result4, weight_hidden3)\n",
    "result6 = ReLU(result5)\n",
    "result7 = np.dot(result6, weight_hidden4)\n",
    "result8 = ReLU(result7)\n",
    "result9 = np.dot(result8, weight_hidden5)\n",
    "result10 = ReLU(result9)\n",
    "result11 = np.dot(result10, weight_output)\n",
    "result12 = Sigmoid(result11)\n",
    "print(result12)\n",
    "print(Y_test)\n",
    "print(len(X_test))\n",
    "error_out = error(result12, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_point = np.array(X_test)\n",
    "result1 = np.dot(single_point, weight_hidden)\n",
    "result2 = ReLU(result1)\n",
    "result3 = np.dot(result2, weight_hidden2) \n",
    "result4 = ReLU(result3)\n",
    "result5 = np.dot(result4, weight_hidden3)\n",
    "result6 = ReLU(result5)\n",
    "result7 = np.dot(result6, weight_hidden4) \n",
    "result8 = ReLU(result7)\n",
    "result9 = np.dot(result8, weight_hidden5)\n",
    "result10 = ReLU(result9)\n",
    "result11 = np.dot(result10, weight_output) \n",
    "result12 = ReLU(result11)\n",
    "print(result12)\n",
    "print(Y_test)\n",
    "print(len(X_test))\n",
    "error_out = error(result12, Y_test)\n",
    "print(math.sqrt(error_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
