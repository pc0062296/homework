{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas \n",
    "import random \n",
    "import time\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv(\"ENB2012_data.csv\")\n",
    "\n",
    "dataframe.columns = ['relative_compactness', 'surface_area', \n",
    "                     'wall_area', 'roof_area', 'overall_height', \n",
    "                     'orientation', 'glazing_area', \n",
    "                     'glazing_area_distribution', 'heating_load', \n",
    "                     'cooling_load']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   relative_compactness  surface_area  wall_area  roof_area  overall_height  \\\n",
      "0                  0.98         514.5      294.0     110.25             7.0   \n",
      "1                  0.98         514.5      294.0     110.25             7.0   \n",
      "2                  0.98         514.5      294.0     110.25             7.0   \n",
      "3                  0.98         514.5      294.0     110.25             7.0   \n",
      "4                  0.90         563.5      318.5     122.50             7.0   \n",
      "\n",
      "   orientation  glazing_area  glazing_area_distribution  heating_load  \\\n",
      "0            2           0.0                          0         15.55   \n",
      "1            3           0.0                          0         15.55   \n",
      "2            4           0.0                          0         15.55   \n",
      "3            5           0.0                          0         15.55   \n",
      "4            2           0.0                          0         20.84   \n",
      "\n",
      "   cooling_load  \n",
      "0         21.33  \n",
      "1         21.33  \n",
      "2         21.33  \n",
      "3         21.33  \n",
      "4         28.28  \n"
     ]
    }
   ],
   "source": [
    "print(dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       relative_compactness  surface_area   wall_area   roof_area  \\\n",
      "count            768.000000    768.000000  768.000000  768.000000   \n",
      "mean               0.764167    671.708333  318.500000  176.604167   \n",
      "std                0.105777     88.086116   43.626481   45.165950   \n",
      "min                0.620000    514.500000  245.000000  110.250000   \n",
      "25%                0.682500    606.375000  294.000000  140.875000   \n",
      "50%                0.750000    673.750000  318.500000  183.750000   \n",
      "75%                0.830000    741.125000  343.000000  220.500000   \n",
      "max                0.980000    808.500000  416.500000  220.500000   \n",
      "\n",
      "       overall_height  orientation  glazing_area  glazing_area_distribution  \\\n",
      "count       768.00000   768.000000    768.000000                  768.00000   \n",
      "mean          5.25000     3.500000      0.234375                    2.81250   \n",
      "std           1.75114     1.118763      0.133221                    1.55096   \n",
      "min           3.50000     2.000000      0.000000                    0.00000   \n",
      "25%           3.50000     2.750000      0.100000                    1.75000   \n",
      "50%           5.25000     3.500000      0.250000                    3.00000   \n",
      "75%           7.00000     4.250000      0.400000                    4.00000   \n",
      "max           7.00000     5.000000      0.400000                    5.00000   \n",
      "\n",
      "       heating_load  cooling_load  \n",
      "count    768.000000    768.000000  \n",
      "mean      22.307201     24.587760  \n",
      "std       10.090196      9.513306  \n",
      "min        6.010000     10.900000  \n",
      "25%       12.992500     15.620000  \n",
      "50%       18.950000     22.080000  \n",
      "75%       31.667500     33.132500  \n",
      "max       43.100000     48.030000  \n"
     ]
    }
   ],
   "source": [
    "print(dataframe.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (768, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape:\", dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types: relative_compactness         float64\n",
      "surface_area                 float64\n",
      "wall_area                    float64\n",
      "roof_area                    float64\n",
      "overall_height               float64\n",
      "orientation                    int64\n",
      "glazing_area                 float64\n",
      "glazing_area_distribution      int64\n",
      "heating_load                 float64\n",
      "cooling_load                 float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Types:\", dataframe.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation:                            relative_compactness  surface_area     wall_area  \\\n",
      "relative_compactness               1.000000e+00 -9.919015e-01 -2.037817e-01   \n",
      "surface_area                      -9.919015e-01  1.000000e+00  1.955016e-01   \n",
      "wall_area                         -2.037817e-01  1.955016e-01  1.000000e+00   \n",
      "roof_area                         -8.688234e-01  8.807195e-01 -2.923165e-01   \n",
      "overall_height                     8.277473e-01 -8.581477e-01  2.809757e-01   \n",
      "orientation                        0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "glazing_area                       1.283986e-17  1.318356e-16 -7.969726e-19   \n",
      "glazing_area_distribution          1.764620e-17 -3.558613e-16  0.000000e+00   \n",
      "heating_load                       6.222722e-01 -6.581202e-01  4.556712e-01   \n",
      "cooling_load                       6.343391e-01 -6.729989e-01  4.271170e-01   \n",
      "\n",
      "                              roof_area  overall_height  orientation  \\\n",
      "relative_compactness      -8.688234e-01    8.277473e-01     0.000000   \n",
      "surface_area               8.807195e-01   -8.581477e-01     0.000000   \n",
      "wall_area                 -2.923165e-01    2.809757e-01     0.000000   \n",
      "roof_area                  1.000000e+00   -9.725122e-01     0.000000   \n",
      "overall_height            -9.725122e-01    1.000000e+00     0.000000   \n",
      "orientation                0.000000e+00    0.000000e+00     1.000000   \n",
      "glazing_area              -1.381805e-16    1.861418e-18     0.000000   \n",
      "glazing_area_distribution -1.079129e-16    0.000000e+00     0.000000   \n",
      "heating_load              -8.618283e-01    8.894307e-01    -0.002587   \n",
      "cooling_load              -8.625466e-01    8.957852e-01     0.014290   \n",
      "\n",
      "                           glazing_area  glazing_area_distribution  \\\n",
      "relative_compactness       1.283986e-17               1.764620e-17   \n",
      "surface_area               1.318356e-16              -3.558613e-16   \n",
      "wall_area                 -7.969726e-19               0.000000e+00   \n",
      "roof_area                 -1.381805e-16              -1.079129e-16   \n",
      "overall_height             1.861418e-18               0.000000e+00   \n",
      "orientation                0.000000e+00               0.000000e+00   \n",
      "glazing_area               1.000000e+00               2.129642e-01   \n",
      "glazing_area_distribution  2.129642e-01               1.000000e+00   \n",
      "heating_load               2.698410e-01               8.736759e-02   \n",
      "cooling_load               2.075050e-01               5.052512e-02   \n",
      "\n",
      "                           heating_load  cooling_load  \n",
      "relative_compactness           0.622272      0.634339  \n",
      "surface_area                  -0.658120     -0.672999  \n",
      "wall_area                      0.455671      0.427117  \n",
      "roof_area                     -0.861828     -0.862547  \n",
      "overall_height                 0.889431      0.895785  \n",
      "orientation                   -0.002587      0.014290  \n",
      "glazing_area                   0.269841      0.207505  \n",
      "glazing_area_distribution      0.087368      0.050525  \n",
      "heating_load                   1.000000      0.975862  \n",
      "cooling_load                   0.975862      1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(\"Correlation:\", dataframe.corr(method='pearson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.800e-01 5.145e+02 2.940e+02 ... 0.000e+00 1.555e+01 2.133e+01]\n",
      " [9.800e-01 5.145e+02 2.940e+02 ... 0.000e+00 1.555e+01 2.133e+01]\n",
      " [9.800e-01 5.145e+02 2.940e+02 ... 0.000e+00 1.555e+01 2.133e+01]\n",
      " ...\n",
      " [6.200e-01 8.085e+02 3.675e+02 ... 5.000e+00 1.644e+01 1.711e+01]\n",
      " [6.200e-01 8.085e+02 3.675e+02 ... 5.000e+00 1.648e+01 1.661e+01]\n",
      " [6.200e-01 8.085e+02 3.675e+02 ... 5.000e+00 1.664e+01 1.603e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.000e-01, 5.635e+02, 3.185e+02, ..., 2.000e+00, 3.327e+01,\n",
       "        3.264e+01],\n",
       "       [7.900e-01, 6.370e+02, 3.430e+02, ..., 4.000e+00, 3.545e+01,\n",
       "        4.186e+01],\n",
       "       [9.000e-01, 5.635e+02, 3.185e+02, ..., 4.000e+00, 3.328e+01,\n",
       "        3.316e+01],\n",
       "       ...,\n",
       "       [6.900e-01, 7.350e+02, 2.940e+02, ..., 2.000e+00, 1.475e+01,\n",
       "        1.644e+01],\n",
       "       [8.600e-01, 5.880e+02, 2.940e+02, ..., 0.000e+00, 1.934e+01,\n",
       "        2.349e+01],\n",
       "       [9.800e-01, 5.145e+02, 2.940e+02, ..., 5.000e+00, 3.272e+01,\n",
       "        3.323e+01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.array(dataframe.values)\n",
    "dataset_shuf = []\n",
    "index_shuf = list(range(len(dataset)))\n",
    "random.shuffle(index_shuf)\n",
    "for i in index_shuf:\n",
    "    dataset_shuf.append(dataset[i,:])   \n",
    "dataset_shuf = np.array(dataset_shuf)\n",
    "dataset_shuf.reshape(768,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32.21],\n",
       "       [35.99],\n",
       "       [32.67],\n",
       "       [25.43],\n",
       "       [14.08],\n",
       "       [13.02],\n",
       "       [19.06],\n",
       "       [14.58],\n",
       "       [29.79],\n",
       "       [14.41],\n",
       "       [37.24],\n",
       "       [31.29],\n",
       "       [28.56],\n",
       "       [28.15],\n",
       "       [24.6 ],\n",
       "       [12.47],\n",
       "       [32.26],\n",
       "       [12.41],\n",
       "       [23.84],\n",
       "       [12.87],\n",
       "       [28.67],\n",
       "       [25.7 ],\n",
       "       [26.84],\n",
       "       [12.43],\n",
       "       [35.73],\n",
       "       [11.42],\n",
       "       [32.31],\n",
       "       [33.27],\n",
       "       [24.4 ],\n",
       "       [32.06],\n",
       "       [16.44],\n",
       "       [11.43],\n",
       "       [41.3 ],\n",
       "       [12.29],\n",
       "       [15.23],\n",
       "       [16.44],\n",
       "       [32.94],\n",
       "       [16.76],\n",
       "       [36.06],\n",
       "       [24.96],\n",
       "       [11.16],\n",
       "       [14.54],\n",
       "       [25.37],\n",
       "       [36.47],\n",
       "       [15.55],\n",
       "       [36.7 ],\n",
       "       [12.86],\n",
       "       [39.86],\n",
       "       [28.17],\n",
       "       [28.95],\n",
       "       [11.18],\n",
       "       [10.77],\n",
       "       [16.86],\n",
       "       [35.48],\n",
       "       [28.61],\n",
       "       [15.36],\n",
       "       [15.41],\n",
       "       [28.63],\n",
       "       [29.67],\n",
       "       [16.66],\n",
       "       [32.73],\n",
       "       [15.16],\n",
       "       [42.08],\n",
       "       [39.86],\n",
       "       [19.12],\n",
       "       [14.54],\n",
       "       [28.09],\n",
       "       [32.82],\n",
       "       [13.  ],\n",
       "       [35.94],\n",
       "       [26.37],\n",
       "       [22.89],\n",
       "       [11.34],\n",
       "       [10.32],\n",
       "       [12.95],\n",
       "       [14.62],\n",
       "       [38.82],\n",
       "       [27.27],\n",
       "       [28.6 ],\n",
       "       [14.21],\n",
       "       [10.7 ],\n",
       "       [ 6.77],\n",
       "       [13.97],\n",
       "       [10.14],\n",
       "       [12.32],\n",
       "       [10.46],\n",
       "       [11.32],\n",
       "       [40.78],\n",
       "       [36.43],\n",
       "       [17.69],\n",
       "       [15.21],\n",
       "       [42.11],\n",
       "       [18.48],\n",
       "       [25.36],\n",
       "       [32.31],\n",
       "       [27.02],\n",
       "       [33.12],\n",
       "       [29.49],\n",
       "       [36.97],\n",
       "       [19.36],\n",
       "       [36.26],\n",
       "       [32.46],\n",
       "       [24.77],\n",
       "       [12.97],\n",
       "       [37.26],\n",
       "       [12.33],\n",
       "       [14.1 ],\n",
       "       [ 6.01],\n",
       "       [28.52],\n",
       "       [12.12],\n",
       "       [12.71],\n",
       "       [10.36],\n",
       "       [27.03],\n",
       "       [ 6.79],\n",
       "       [14.39],\n",
       "       [29.22],\n",
       "       [14.12],\n",
       "       [38.57],\n",
       "       [11.22],\n",
       "       [15.34],\n",
       "       [32.15],\n",
       "       [36.45],\n",
       "       [28.37],\n",
       "       [10.64],\n",
       "       [13.94],\n",
       "       [26.97],\n",
       "       [28.91],\n",
       "       [34.29],\n",
       "       [10.39],\n",
       "       [32.67],\n",
       "       [16.69],\n",
       "       [ 8.5 ],\n",
       "       [36.06],\n",
       "       [13.04],\n",
       "       [14.5 ],\n",
       "       [14.53],\n",
       "       [24.03],\n",
       "       [35.69],\n",
       "       [12.63],\n",
       "       [28.31],\n",
       "       [18.31],\n",
       "       [12.25],\n",
       "       [12.18],\n",
       "       [28.05],\n",
       "       [41.32],\n",
       "       [12.97],\n",
       "       [39.31],\n",
       "       [11.69],\n",
       "       [36.64],\n",
       "       [24.17],\n",
       "       [ 8.49],\n",
       "       [15.34],\n",
       "       [11.45],\n",
       "       [12.73],\n",
       "       [36.71],\n",
       "       [13.  ],\n",
       "       [24.23],\n",
       "       [10.45],\n",
       "       [32.85],\n",
       "       [10.75],\n",
       "       [28.15],\n",
       "       [11.22],\n",
       "       [12.82],\n",
       "       [35.65],\n",
       "       [42.74],\n",
       "       [10.47],\n",
       "       [28.62],\n",
       "       [14.61],\n",
       "       [29.01],\n",
       "       [10.07],\n",
       "       [39.81],\n",
       "       [29.83],\n",
       "       [17.41],\n",
       "       [36.57],\n",
       "       [17.88],\n",
       "       [10.66],\n",
       "       [32.23],\n",
       "       [ 7.1 ],\n",
       "       [28.67],\n",
       "       [32.21],\n",
       "       [32.05],\n",
       "       [10.85],\n",
       "       [35.96],\n",
       "       [11.2 ],\n",
       "       [23.75],\n",
       "       [12.67],\n",
       "       [16.83],\n",
       "       [29.53],\n",
       "       [41.09],\n",
       "       [14.75],\n",
       "       [19.34],\n",
       "       [32.72]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = dataset_shuf[:576,0:8]\n",
    "Y_train = dataset_shuf[:576,8:9]\n",
    "X_train.reshape(576,8)\n",
    "Y_train.reshape(576,1)\n",
    "\n",
    "X_test = dataset_shuf[576:,0:8]\n",
    "Y_test = dataset_shuf[576:,8:9]\n",
    "X_test.reshape(192,8)\n",
    "Y_test.reshape(192,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ColumnTransformer([('one_hot_encoder', OneHotEncoder(), [5,7])],remainder='passthrough')\n",
    "X_train = np.array(transformer.fit_transform(X_train), dtype=np.float)\n",
    "\n",
    "X_test = np.array(transformer.fit_transform(X_test), dtype=np.float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>612.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>147.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>735.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>220.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>686.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>220.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>735.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>220.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>710.5</td>\n",
       "      <td>269.5</td>\n",
       "      <td>220.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>710.5</td>\n",
       "      <td>269.5</td>\n",
       "      <td>220.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>784.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>220.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9    10     11     12  \\\n",
       "0    0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.90  563.5  318.5   \n",
       "1    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.79  637.0  343.0   \n",
       "2    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.90  563.5  318.5   \n",
       "3    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.82  612.5  318.5   \n",
       "4    0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.69  735.0  294.0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...    ...    ...   \n",
       "571  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.74  686.0  245.0   \n",
       "572  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.69  735.0  294.0   \n",
       "573  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.71  710.5  269.5   \n",
       "574  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.71  710.5  269.5   \n",
       "575  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.64  784.0  343.0   \n",
       "\n",
       "        13   14    15  \n",
       "0    122.5  7.0  0.25  \n",
       "1    147.0  7.0  0.10  \n",
       "2    122.5  7.0  0.25  \n",
       "3    147.0  7.0  0.40  \n",
       "4    220.5  3.5  0.25  \n",
       "..     ...  ...   ...  \n",
       "571  220.5  3.5  0.25  \n",
       "572  220.5  3.5  0.40  \n",
       "573  220.5  3.5  0.00  \n",
       "574  220.5  3.5  0.40  \n",
       "575  220.5  3.5  0.25  \n",
       "\n",
       "[576 rows x 16 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = np.copy(X_train[:,10:16])\n",
    "X_scaled2 = np.copy(X_test[:,10:16])\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_scaled)\n",
    "\n",
    "X_scaled = scaler.transform(X_scaled)\n",
    "X_scaled2 = scaler.transform(X_scaled2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.317978</td>\n",
       "      <td>-1.255403</td>\n",
       "      <td>-0.011626</td>\n",
       "      <td>-1.224903</td>\n",
       "      <td>1.021055</td>\n",
       "      <td>0.126122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.273094</td>\n",
       "      <td>-0.422005</td>\n",
       "      <td>0.546401</td>\n",
       "      <td>-0.680291</td>\n",
       "      <td>1.021055</td>\n",
       "      <td>-1.014916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.317978</td>\n",
       "      <td>-1.255403</td>\n",
       "      <td>-0.011626</td>\n",
       "      <td>-1.224903</td>\n",
       "      <td>1.021055</td>\n",
       "      <td>0.126122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.558063</td>\n",
       "      <td>-0.699804</td>\n",
       "      <td>-0.011626</td>\n",
       "      <td>-0.680291</td>\n",
       "      <td>1.021055</td>\n",
       "      <td>1.267160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.676799</td>\n",
       "      <td>0.689194</td>\n",
       "      <td>-0.569652</td>\n",
       "      <td>0.953543</td>\n",
       "      <td>-0.979379</td>\n",
       "      <td>0.126122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.201852</td>\n",
       "      <td>0.133595</td>\n",
       "      <td>-1.685705</td>\n",
       "      <td>0.953543</td>\n",
       "      <td>-0.979379</td>\n",
       "      <td>0.126122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.676799</td>\n",
       "      <td>0.689194</td>\n",
       "      <td>-0.569652</td>\n",
       "      <td>0.953543</td>\n",
       "      <td>-0.979379</td>\n",
       "      <td>1.267160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.486821</td>\n",
       "      <td>0.411394</td>\n",
       "      <td>-1.127678</td>\n",
       "      <td>0.953543</td>\n",
       "      <td>-0.979379</td>\n",
       "      <td>-1.775608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.486821</td>\n",
       "      <td>0.411394</td>\n",
       "      <td>-1.127678</td>\n",
       "      <td>0.953543</td>\n",
       "      <td>-0.979379</td>\n",
       "      <td>1.267160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.151746</td>\n",
       "      <td>1.244793</td>\n",
       "      <td>0.546401</td>\n",
       "      <td>0.953543</td>\n",
       "      <td>-0.979379</td>\n",
       "      <td>0.126122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9        10        11  \\\n",
       "0    0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.317978 -1.255403   \n",
       "1    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.273094 -0.422005   \n",
       "2    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.317978 -1.255403   \n",
       "3    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.558063 -0.699804   \n",
       "4    0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 -0.676799  0.689194   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...       ...   \n",
       "571  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 -0.201852  0.133595   \n",
       "572  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0 -0.676799  0.689194   \n",
       "573  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0 -0.486821  0.411394   \n",
       "574  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 -0.486821  0.411394   \n",
       "575  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 -1.151746  1.244793   \n",
       "\n",
       "           12        13        14        15  \n",
       "0   -0.011626 -1.224903  1.021055  0.126122  \n",
       "1    0.546401 -0.680291  1.021055 -1.014916  \n",
       "2   -0.011626 -1.224903  1.021055  0.126122  \n",
       "3   -0.011626 -0.680291  1.021055  1.267160  \n",
       "4   -0.569652  0.953543 -0.979379  0.126122  \n",
       "..        ...       ...       ...       ...  \n",
       "571 -1.685705  0.953543 -0.979379  0.126122  \n",
       "572 -0.569652  0.953543 -0.979379  1.267160  \n",
       "573 -1.127678  0.953543 -0.979379 -1.775608  \n",
       "574 -1.127678  0.953543 -0.979379  1.267160  \n",
       "575  0.546401  0.953543 -0.979379  0.126122  \n",
       "\n",
       "[576 rows x 16 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.copy(X_train[:,0:10])\n",
    "X_test = np.copy(X_test[:,0:10])\n",
    "X_train = np.append(X_train, X_scaled, axis = 1)\n",
    "X_test = np.append(X_test, X_scaled2, axis = 1)\n",
    "\n",
    "pandas.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define weight:\n",
    "\n",
    "#7 for hidden layer1\n",
    "#5 for hidden layer2\n",
    "#2 for output layer\n",
    "#9 total\n",
    "\n",
    "weight_hidden = np.random.random((16,64))-0.5\n",
    "weight_hidden2 = np.random.random((64,64))-0.5\n",
    "weight_hidden3 = np.random.random((64,64))-0.5\n",
    "weight_hidden4 = np.random.random((64,64))-0.5\n",
    "weight_hidden5 = np.random.random((64,8))-0.5\n",
    "weight_output = np.random.random((8,1))-0.5\n",
    "lr = 0.00001\n",
    "bias = 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x) :\n",
    "    return x * (x > 0) + 0.01 * x * (x <= 0)\n",
    "\n",
    "def ReLU_der(x) :\n",
    "    return 1 * (x > 0) + 0.01 * (x <= 0)\n",
    "\n",
    "def limit(x) :  \n",
    "    while(np.max(x) > 0.1 or np.min(x) < -0.1) : \n",
    "            x /= 10\n",
    "    return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now training  0.0 %\n",
      "54914.88055032281\n",
      "now training  0.1 %\n",
      "54866.23993532467\n",
      "now training  0.2 %\n",
      "54942.731379637655\n",
      "now training  0.3 %\n",
      "54890.87300627182\n",
      "now training  0.4 %\n",
      "54894.41917655515\n",
      "now training  0.5 %\n",
      "54880.80490654864\n",
      "now training  0.6 %\n",
      "54928.02011536254\n",
      "now training  0.7 %\n",
      "54922.832906969066\n",
      "now training  0.8 %\n",
      "54916.853358056695\n",
      "now training  0.9 %\n",
      "54859.28870567559\n",
      "now training  1.0 %\n",
      "54876.75482761553\n",
      "now training  1.1 %\n",
      "54928.97544038393\n",
      "now training  1.2 %\n",
      "54947.913163416335\n",
      "now training  1.3 %\n",
      "54964.93870757283\n",
      "now training  1.4 %\n",
      "54953.91605897802\n",
      "now training  1.5 %\n",
      "54948.0262399239\n",
      "now training  1.6 %\n",
      "54978.36518269286\n",
      "now training  1.7 %\n",
      "54971.23158580596\n",
      "now training  1.8 %\n",
      "54922.78150602102\n",
      "now training  1.9 %\n",
      "54914.22403662032\n",
      "now training  2.0 %\n",
      "54939.15462107598\n",
      "now training  2.1 %\n",
      "54981.63244573098\n",
      "now training  2.2 %\n",
      "54917.40026300587\n",
      "now training  2.3 %\n",
      "54876.38962103727\n",
      "now training  2.4 %\n",
      "54966.89698355668\n",
      "now training  2.5 %\n",
      "54969.24871680123\n",
      "now training  2.6 %\n",
      "55006.83515650331\n",
      "now training  2.7 %\n",
      "54940.62995529318\n",
      "now training  2.8 %\n",
      "54964.52350284095\n",
      "now training  2.9 %\n",
      "54970.24179043314\n",
      "now training  3.0 %\n",
      "54952.59910777294\n",
      "now training  3.1 %\n",
      "54909.07144548165\n",
      "now training  3.2 %\n",
      "54945.182449194996\n",
      "now training  3.3 %\n",
      "54948.829153051556\n",
      "now training  3.4 %\n",
      "54919.970778260176\n",
      "now training  3.5 %\n",
      "54904.4473360813\n",
      "now training  3.6 %\n",
      "54979.741352773184\n",
      "now training  3.7 %\n",
      "55030.73439914753\n",
      "now training  3.8 %\n",
      "54957.826902389555\n",
      "now training  3.9 %\n",
      "54977.1849047005\n",
      "now training  4.0 %\n",
      "55002.8405916021\n",
      "now training  4.1 %\n",
      "55012.188736222495\n",
      "now training  4.2 %\n",
      "54994.596557975674\n",
      "now training  4.3 %\n",
      "54981.02083902844\n",
      "now training  4.4 %\n",
      "54992.99719373603\n",
      "now training  4.5 %\n",
      "55024.34439882015\n",
      "now training  4.6 %\n",
      "54962.35145601471\n",
      "now training  4.7 %\n",
      "55037.55277196596\n",
      "now training  4.8 %\n",
      "54967.102983313365\n",
      "now training  4.9 %\n",
      "54989.230040767274\n",
      "now training  5.0 %\n",
      "54994.59906460656\n",
      "now training  5.1 %\n",
      "54971.3081341949\n",
      "now training  5.2 %\n",
      "54991.189055254436\n",
      "now training  5.3 %\n",
      "55000.14267390764\n",
      "now training  5.4 %\n",
      "55039.23948147951\n",
      "now training  5.5 %\n",
      "55040.221439250236\n",
      "now training  5.6 %\n",
      "55059.61657407987\n",
      "now training  5.7 %\n",
      "55036.77090005757\n",
      "now training  5.8 %\n",
      "55038.47400629244\n",
      "now training  5.9 %\n",
      "55038.19506719241\n",
      "now training  6.0 %\n",
      "55042.841033615\n",
      "now training  6.1 %\n",
      "55067.98013521076\n",
      "now training  6.2 %\n",
      "55050.58543874418\n",
      "now training  6.3 %\n",
      "55056.429568403066\n",
      "now training  6.4 %\n",
      "55036.21280214882\n",
      "now training  6.5 %\n",
      "55026.923329402896\n",
      "now training  6.6 %\n",
      "55038.307425650164\n",
      "now training  6.7 %\n",
      "55073.49398504805\n",
      "now training  6.8 %\n",
      "55079.88976714511\n",
      "now training  6.9 %\n",
      "55057.276179403714\n",
      "now training  7.0 %\n",
      "55046.27903821239\n",
      "now training  7.1 %\n",
      "55022.80288158469\n",
      "now training  7.2 %\n",
      "55048.24734730429\n",
      "now training  7.3 %\n",
      "55069.422665145976\n",
      "now training  7.4 %\n",
      "55057.2405963807\n",
      "now training  7.5 %\n",
      "55050.105359685025\n",
      "now training  7.6 %\n",
      "55052.56091269344\n",
      "now training  7.7 %\n",
      "55089.30503949464\n",
      "now training  7.8 %\n",
      "55018.55207767084\n",
      "now training  7.9 %\n",
      "55082.815580092865\n",
      "now training  8.0 %\n",
      "55111.40505176175\n",
      "now training  8.1 %\n",
      "55064.4050004713\n",
      "now training  8.2 %\n",
      "55052.12522387473\n",
      "now training  8.3 %\n",
      "55090.72653183877\n",
      "now training  8.4 %\n",
      "55091.152395813304\n",
      "now training  8.5 %\n",
      "55094.48832496552\n",
      "now training  8.6 %\n",
      "55118.14109927909\n",
      "now training  8.7 %\n",
      "55079.15646416615\n",
      "now training  8.8 %\n",
      "55120.603850527456\n",
      "now training  8.9 %\n",
      "55052.48496894955\n",
      "now training  9.0 %\n",
      "55085.83878068436\n",
      "now training  9.1 %\n",
      "55092.802910467646\n",
      "now training  9.2 %\n",
      "55092.643079873\n",
      "now training  9.3 %\n",
      "55120.77732210315\n",
      "now training  9.4 %\n",
      "55127.77679855959\n",
      "now training  9.5 %\n",
      "55179.326531260805\n",
      "now training  9.6 %\n",
      "55144.98145672366\n",
      "now training  9.7 %\n",
      "55111.39389325424\n",
      "now training  9.8 %\n",
      "55135.91566319397\n",
      "now training  9.9 %\n",
      "55129.88908473069\n",
      "now training  10.0 %\n",
      "55112.67071330747\n",
      "now training  10.1 %\n",
      "55143.86948361575\n",
      "now training  10.2 %\n",
      "55165.221917906456\n",
      "now training  10.3 %\n",
      "55134.77033102827\n",
      "now training  10.4 %\n",
      "55158.367335341085\n",
      "now training  10.5 %\n",
      "55132.67241973608\n",
      "now training  10.6 %\n",
      "55103.349269851446\n",
      "now training  10.7 %\n",
      "55117.362488927916\n",
      "now training  10.8 %\n",
      "55149.6345064031\n",
      "now training  10.9 %\n",
      "55156.842620171126\n",
      "now training  11.0 %\n",
      "55162.04050593561\n",
      "now training  11.1 %\n",
      "55111.20308008897\n",
      "now training  11.2 %\n",
      "55120.33307820941\n",
      "now training  11.3 %\n",
      "55153.55194570871\n",
      "now training  11.4 %\n",
      "55151.033590434905\n",
      "now training  11.5 %\n",
      "55180.33087734931\n",
      "now training  11.6 %\n",
      "55161.35218681304\n",
      "now training  11.7 %\n",
      "55158.95607729946\n",
      "now training  11.8 %\n",
      "55168.27658501168\n",
      "now training  11.9 %\n",
      "55185.55452102129\n",
      "now training  12.0 %\n",
      "55176.61581678211\n",
      "now training  12.1 %\n",
      "55146.6621925298\n",
      "now training  12.2 %\n",
      "55166.696551584966\n",
      "now training  12.3 %\n",
      "55150.989465179206\n",
      "now training  12.4 %\n",
      "55187.704941011725\n",
      "now training  12.5 %\n",
      "55207.91617638832\n",
      "now training  12.6 %\n",
      "55175.05576752161\n",
      "now training  12.7 %\n",
      "55163.27179190856\n",
      "now training  12.8 %\n",
      "55189.841369493006\n",
      "now training  12.9 %\n",
      "55229.73482509624\n",
      "now training  13.0 %\n",
      "55209.78763476215\n",
      "now training  13.1 %\n",
      "55186.44313066139\n",
      "now training  13.2 %\n",
      "55204.35057107921\n",
      "now training  13.3 %\n",
      "55216.916661395335\n",
      "now training  13.4 %\n",
      "55205.13288955738\n",
      "now training  13.5 %\n",
      "55208.59190714832\n",
      "now training  13.6 %\n",
      "55243.33424043139\n",
      "now training  13.7 %\n",
      "55249.05170119009\n",
      "now training  13.8 %\n",
      "55191.63058088046\n",
      "now training  13.9 %\n",
      "55197.728486174834\n",
      "now training  14.0 %\n",
      "55253.31865516703\n",
      "now training  14.1 %\n",
      "55237.42313376725\n",
      "now training  14.2 %\n",
      "55250.32364216757\n",
      "now training  14.3 %\n",
      "55236.516289230145\n",
      "now training  14.4 %\n",
      "55261.99967903584\n",
      "now training  14.5 %\n",
      "55214.60832252684\n",
      "now training  14.6 %\n",
      "55287.20282082737\n",
      "now training  14.7 %\n",
      "55277.10616262059\n",
      "now training  14.8 %\n",
      "55291.52712255757\n",
      "now training  14.9 %\n",
      "55270.253945178585\n",
      "now training  15.0 %\n",
      "55287.7486808604\n",
      "now training  15.1 %\n",
      "55252.32504675626\n",
      "now training  15.2 %\n",
      "55279.862885981056\n",
      "now training  15.3 %\n",
      "55266.866605731906\n",
      "now training  15.4 %\n",
      "55269.18083948757\n",
      "now training  15.5 %\n",
      "55259.92974727601\n",
      "now training  15.6 %\n",
      "55294.56861463909\n",
      "now training  15.7 %\n",
      "55300.29678196852\n",
      "now training  15.8 %\n",
      "55321.92858712682\n",
      "now training  15.9 %\n",
      "55297.60302861867\n",
      "now training  16.0 %\n",
      "55292.618557232505\n",
      "now training  16.1 %\n",
      "55310.360299016844\n",
      "now training  16.2 %\n",
      "55268.70365172267\n",
      "now training  16.3 %\n",
      "55283.75257284728\n",
      "now training  16.4 %\n",
      "55309.016225909414\n",
      "now training  16.5 %\n",
      "55304.067748672926\n",
      "now training  16.6 %\n",
      "55325.54313351313\n",
      "now training  16.7 %\n",
      "55312.83701258202\n",
      "now training  16.8 %\n",
      "55321.710160069284\n",
      "now training  16.9 %\n",
      "55336.70314136967\n",
      "now training  17.0 %\n",
      "55335.43519137564\n",
      "now training  17.1 %\n",
      "55365.261965729005\n",
      "now training  17.2 %\n",
      "55377.086756592806\n",
      "now training  17.3 %\n",
      "55339.24026328957\n",
      "now training  17.4 %\n",
      "55339.28254375986\n",
      "now training  17.5 %\n",
      "55345.63803255085\n",
      "now training  17.6 %\n",
      "55359.980885308076\n",
      "now training  17.7 %\n",
      "55356.13613627698\n",
      "now training  17.8 %\n",
      "55352.46203255227\n",
      "now training  17.9 %\n",
      "55366.16648217819\n",
      "now training  18.0 %\n",
      "55377.842480259715\n",
      "now training  18.1 %\n",
      "55339.396354101824\n",
      "now training  18.2 %\n",
      "55356.01820458242\n",
      "now training  18.3 %\n",
      "55398.14530355323\n",
      "now training  18.4 %\n",
      "55355.69852447101\n",
      "now training  18.5 %\n",
      "55367.48163774522\n",
      "now training  18.6 %\n",
      "55387.52107172146\n",
      "now training  18.7 %\n",
      "55392.806705799056\n",
      "now training  18.8 %\n",
      "55396.08235656863\n",
      "now training  18.9 %\n",
      "55394.88535244374\n",
      "now training  19.0 %\n",
      "55373.2195595989\n",
      "now training  19.1 %\n",
      "55414.87105019143\n",
      "now training  19.2 %\n",
      "55389.156730741\n",
      "now training  19.3 %\n",
      "55399.286903226544\n",
      "now training  19.4 %\n",
      "55401.57538816057\n",
      "now training  19.5 %\n",
      "55419.72549515884\n",
      "now training  19.6 %\n",
      "55399.347902003996\n",
      "now training  19.7 %\n",
      "55416.41263163475\n",
      "now training  19.8 %\n",
      "55410.44866768019\n",
      "now training  19.9 %\n",
      "55411.459894510976\n",
      "now training  20.0 %\n",
      "55429.97119635227\n",
      "now training  20.1 %\n",
      "55405.289818245634\n",
      "now training  20.2 %\n",
      "55425.17198949776\n",
      "now training  20.3 %\n",
      "55404.17299474613\n",
      "now training  20.4 %\n",
      "55425.46140789115\n",
      "now training  20.5 %\n",
      "55410.32070430357\n",
      "now training  20.6 %\n",
      "55387.74357852765\n",
      "now training  20.7 %\n",
      "55421.677204375825\n",
      "now training  20.8 %\n",
      "55433.29176536724\n",
      "now training  20.9 %\n",
      "55441.49992123587\n",
      "now training  21.0 %\n",
      "55441.56088059496\n",
      "now training  21.1 %\n",
      "55457.441903789775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now training  21.2 %\n",
      "55460.44817600155\n",
      "now training  21.3 %\n",
      "55438.23535857542\n",
      "now training  21.4 %\n",
      "55450.68725063418\n",
      "now training  21.5 %\n",
      "55456.031452165465\n",
      "now training  21.6 %\n",
      "55438.92908761816\n",
      "now training  21.7 %\n",
      "55432.46058639086\n",
      "now training  21.8 %\n",
      "55468.0109777083\n",
      "now training  21.9 %\n",
      "55425.670048739375\n",
      "now training  22.0 %\n",
      "55425.48917606672\n",
      "now training  22.1 %\n",
      "55470.70417607791\n",
      "now training  22.2 %\n",
      "55482.86913301346\n",
      "now training  22.3 %\n",
      "55467.18045676834\n",
      "now training  22.4 %\n",
      "55455.95378879049\n",
      "now training  22.5 %\n",
      "55450.49922050114\n",
      "now training  22.6 %\n",
      "55463.80499780591\n",
      "now training  22.7 %\n",
      "55464.620671170094\n",
      "now training  22.8 %\n",
      "55463.9213087615\n",
      "now training  22.9 %\n",
      "55460.787014750254\n",
      "now training  23.0 %\n",
      "55476.37879103748\n",
      "now training  23.1 %\n",
      "55486.37718398281\n",
      "now training  23.2 %\n",
      "55510.87713300921\n",
      "now training  23.3 %\n",
      "55490.239049183736\n",
      "now training  23.4 %\n",
      "55489.44180791537\n",
      "now training  23.5 %\n",
      "55479.28530573822\n",
      "now training  23.6 %\n",
      "55501.10361304809\n",
      "now training  23.7 %\n",
      "55510.44679987539\n",
      "now training  23.8 %\n",
      "55500.81123853412\n",
      "now training  23.9 %\n",
      "55511.24387909619\n",
      "now training  24.0 %\n",
      "55498.69730468806\n",
      "now training  24.1 %\n",
      "55488.49567567841\n",
      "now training  24.2 %\n",
      "55468.600978693205\n",
      "now training  24.3 %\n",
      "55476.68735597932\n",
      "now training  24.4 %\n",
      "55502.49438220705\n",
      "now training  24.5 %\n",
      "55503.64089015107\n",
      "now training  24.6 %\n",
      "55499.554003538455\n",
      "now training  24.7 %\n",
      "55514.79391119663\n",
      "now training  24.8 %\n",
      "55498.140518600114\n",
      "now training  24.9 %\n",
      "55461.27366269524\n",
      "now training  25.0 %\n",
      "55509.68009442258\n",
      "now training  25.1 %\n",
      "55493.52638694762\n",
      "now training  25.2 %\n",
      "55500.87691742927\n",
      "now training  25.3 %\n",
      "55511.586844365185\n",
      "now training  25.4 %\n",
      "55517.8094155384\n",
      "now training  25.5 %\n",
      "55522.22305056479\n",
      "now training  25.6 %\n",
      "55522.22340991861\n",
      "now training  25.7 %\n",
      "55504.405046907224\n",
      "now training  25.8 %\n",
      "55509.530808492134\n",
      "now training  25.9 %\n",
      "55541.434417075\n",
      "now training  26.0 %\n",
      "55518.33020780474\n",
      "now training  26.1 %\n",
      "55504.97673225536\n",
      "now training  26.2 %\n",
      "55524.21934626865\n",
      "now training  26.3 %\n",
      "55528.0860340478\n",
      "now training  26.4 %\n",
      "55514.52541201684\n",
      "now training  26.5 %\n",
      "55526.94312799953\n",
      "now training  26.6 %\n",
      "55530.59207287713\n",
      "now training  26.7 %\n",
      "55530.29195259698\n",
      "now training  26.8 %\n",
      "55524.15067622012\n",
      "now training  26.9 %\n",
      "55524.917213818015\n",
      "now training  27.0 %\n",
      "55524.461719129526\n",
      "now training  27.1 %\n",
      "55547.44888585333\n",
      "now training  27.2 %\n",
      "55526.54009101633\n",
      "now training  27.3 %\n",
      "55536.79160587323\n",
      "now training  27.4 %\n",
      "55535.05236058414\n",
      "now training  27.5 %\n",
      "55546.36339362072\n",
      "now training  27.6 %\n",
      "55544.555888534065\n",
      "now training  27.7 %\n",
      "55528.421781281075\n",
      "now training  27.8 %\n",
      "55551.55665564512\n",
      "now training  27.9 %\n",
      "55532.48093011141\n",
      "now training  28.0 %\n",
      "55526.81113740119\n",
      "now training  28.1 %\n",
      "55553.056077294874\n",
      "now training  28.2 %\n",
      "55549.721986102886\n",
      "now training  28.3 %\n",
      "55534.26383854431\n",
      "now training  28.4 %\n",
      "55525.00734570759\n",
      "now training  28.5 %\n",
      "55557.10041921077\n",
      "now training  28.6 %\n",
      "55543.87491324281\n",
      "now training  28.7 %\n",
      "55536.70973975146\n",
      "now training  28.8 %\n",
      "55558.15599356802\n",
      "now training  28.9 %\n",
      "55554.236360430965\n",
      "now training  29.0 %\n",
      "55529.32953612316\n",
      "now training  29.1 %\n",
      "55547.26649557747\n",
      "now training  29.2 %\n",
      "55551.605760814506\n",
      "now training  29.3 %\n",
      "55542.56713873001\n",
      "now training  29.4 %\n",
      "55541.20847857554\n",
      "now training  29.5 %\n",
      "55564.908628970785\n",
      "now training  29.6 %\n",
      "55552.29813307256\n",
      "now training  29.7 %\n",
      "55541.34861628353\n",
      "now training  29.8 %\n",
      "55545.27973044463\n",
      "now training  29.9 %\n",
      "55537.86699515729\n",
      "now training  30.0 %\n",
      "55541.515368182845\n",
      "now training  30.1 %\n",
      "55539.28566767444\n",
      "now training  30.2 %\n",
      "55557.721016147996\n",
      "now training  30.3 %\n",
      "55547.42866075401\n",
      "now training  30.4 %\n",
      "55549.072559386696\n",
      "now training  30.5 %\n",
      "55554.08081298975\n",
      "now training  30.6 %\n",
      "55562.19412235889\n",
      "now training  30.7 %\n",
      "55549.494907362714\n",
      "now training  30.8 %\n",
      "55551.74797341555\n",
      "now training  30.9 %\n",
      "55532.751261663005\n",
      "now training  31.0 %\n",
      "55535.51622437191\n",
      "now training  31.1 %\n",
      "55548.45572754061\n",
      "now training  31.2 %\n",
      "55551.902474094044\n",
      "now training  31.3 %\n",
      "55554.90060532535\n",
      "now training  31.4 %\n",
      "55547.63470428351\n",
      "now training  31.5 %\n",
      "55542.17213481711\n",
      "now training  31.6 %\n",
      "55562.444256880415\n",
      "now training  31.7 %\n",
      "55545.59189277107\n",
      "now training  31.8 %\n",
      "55564.25645542378\n",
      "now training  31.9 %\n",
      "55556.43474659225\n",
      "now training  32.0 %\n",
      "55544.80002451387\n",
      "now training  32.1 %\n",
      "55549.05526553332\n",
      "now training  32.2 %\n",
      "55557.902668982744\n",
      "now training  32.3 %\n",
      "55553.34518212745\n",
      "now training  32.4 %\n",
      "55547.62528890978\n",
      "now training  32.5 %\n",
      "55553.02845520424\n",
      "now training  32.6 %\n",
      "55550.5857581898\n",
      "now training  32.7 %\n",
      "55542.79854381221\n",
      "now training  32.8 %\n",
      "55558.35113627728\n",
      "now training  32.9 %\n",
      "55569.151321177305\n",
      "now training  33.0 %\n",
      "55547.61488864108\n",
      "now training  33.1 %\n",
      "55541.48502674065\n",
      "now training  33.2 %\n",
      "55570.05610826113\n",
      "now training  33.3 %\n",
      "55562.92146960263\n",
      "now training  33.4 %\n",
      "55563.63562583181\n",
      "now training  33.5 %\n",
      "55559.66429469206\n",
      "now training  33.6 %\n",
      "55579.2039667795\n",
      "now training  33.7 %\n",
      "55555.33952050188\n",
      "now training  33.8 %\n",
      "55534.290516821304\n",
      "now training  33.9 %\n",
      "55563.50063703961\n",
      "now training  34.0 %\n",
      "55554.53381573389\n",
      "now training  34.1 %\n",
      "55547.78143995362\n",
      "now training  34.2 %\n",
      "55553.6969998492\n",
      "now training  34.3 %\n",
      "55547.023597819425\n",
      "now training  34.4 %\n",
      "55553.9602470872\n",
      "now training  34.5 %\n",
      "55547.793128067424\n",
      "now training  34.6 %\n",
      "55542.554307825514\n",
      "now training  34.7 %\n",
      "55560.29411202004\n",
      "now training  34.8 %\n",
      "55572.59512585943\n",
      "now training  34.9 %\n",
      "55557.58739436892\n",
      "now training  35.0 %\n",
      "55571.41560750981\n",
      "now training  35.1 %\n",
      "55562.420651002394\n",
      "now training  35.2 %\n",
      "55567.96235198559\n",
      "now training  35.3 %\n",
      "55566.37900247947\n",
      "now training  35.4 %\n",
      "55551.21118031633\n",
      "now training  35.5 %\n",
      "55552.00132054674\n",
      "now training  35.6 %\n",
      "55555.07071281946\n",
      "now training  35.7 %\n",
      "55560.6002877688\n",
      "now training  35.8 %\n",
      "55555.70150735778\n",
      "now training  35.9 %\n",
      "55565.61430425583\n",
      "now training  36.0 %\n",
      "55565.11440915276\n",
      "now training  36.1 %\n",
      "55549.885709516064\n",
      "now training  36.2 %\n",
      "55574.524635107904\n",
      "now training  36.3 %\n",
      "55568.12859739067\n",
      "now training  36.4 %\n",
      "55569.656426201895\n",
      "now training  36.5 %\n",
      "55552.600130265404\n",
      "now training  36.6 %\n",
      "55562.25263094528\n",
      "now training  36.7 %\n",
      "55562.10471474772\n",
      "now training  36.8 %\n",
      "55562.54171580532\n",
      "now training  36.9 %\n",
      "55563.55765806455\n",
      "now training  37.0 %\n",
      "55558.920875575364\n",
      "now training  37.1 %\n",
      "55563.82334251157\n",
      "now training  37.2 %\n",
      "55566.964548977296\n",
      "now training  37.3 %\n",
      "55570.72683267412\n",
      "now training  37.4 %\n",
      "55571.20837482369\n",
      "now training  37.5 %\n",
      "55561.76321166161\n",
      "now training  37.6 %\n",
      "55564.68533231602\n",
      "now training  37.7 %\n",
      "55584.358976137766\n",
      "now training  37.8 %\n",
      "55574.36059535721\n",
      "now training  37.9 %\n",
      "55562.38801908912\n",
      "now training  38.0 %\n",
      "55567.738609704946\n",
      "now training  38.1 %\n",
      "55560.53159574191\n",
      "now training  38.2 %\n",
      "55584.49045216554\n",
      "now training  38.3 %\n",
      "55570.621236829335\n",
      "now training  38.4 %\n",
      "55563.96118723137\n",
      "now training  38.5 %\n",
      "55558.72709749687\n",
      "now training  38.6 %\n",
      "55571.71423628926\n",
      "now training  38.7 %\n",
      "55580.74075038674\n",
      "now training  38.8 %\n",
      "55571.28896862857\n",
      "now training  38.9 %\n",
      "55588.7141874951\n",
      "now training  39.0 %\n",
      "55581.80555600587\n",
      "now training  39.1 %\n",
      "55563.45195092738\n",
      "now training  39.2 %\n",
      "55566.16658090439\n",
      "now training  39.3 %\n",
      "55576.55205209314\n",
      "now training  39.4 %\n",
      "55567.056699403605\n",
      "now training  39.5 %\n",
      "55587.02803129852\n",
      "now training  39.6 %\n",
      "55572.05442163917\n",
      "now training  39.7 %\n",
      "55587.33237195492\n",
      "now training  39.8 %\n",
      "55579.30646344243\n",
      "now training  39.9 %\n",
      "55557.22400908484\n",
      "now training  40.0 %\n",
      "55576.57556920623\n",
      "now training  40.1 %\n",
      "55581.50595485585\n",
      "now training  40.2 %\n",
      "55575.26466266008\n",
      "now training  40.3 %\n",
      "55572.19762214285\n",
      "now training  40.4 %\n",
      "55574.47959619316\n",
      "now training  40.5 %\n",
      "55568.541568163884\n",
      "now training  40.6 %\n",
      "55573.832781394536\n",
      "now training  40.7 %\n",
      "55583.35094984181\n",
      "now training  40.8 %\n",
      "55569.890768958736\n",
      "now training  40.9 %\n",
      "55579.56077847248\n",
      "now training  41.0 %\n",
      "55578.22704049732\n",
      "now training  41.1 %\n",
      "55582.61841384313\n",
      "now training  41.2 %\n",
      "55570.229999485164\n",
      "now training  41.3 %\n",
      "55572.97520977802\n",
      "now training  41.4 %\n",
      "55567.87757870677\n",
      "now training  41.5 %\n",
      "55574.24427541105\n",
      "now training  41.6 %\n",
      "55579.886017358745\n",
      "now training  41.7 %\n",
      "55577.45332400978\n",
      "now training  41.8 %\n",
      "55578.363041059005\n",
      "now training  41.9 %\n",
      "55576.283838643896\n",
      "now training  42.0 %\n",
      "55575.982206488676\n",
      "now training  42.1 %\n",
      "55567.10043141791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now training  42.2 %\n",
      "55575.03695604788\n",
      "now training  42.3 %\n",
      "55579.4745172816\n",
      "now training  42.4 %\n",
      "55570.27855976\n",
      "now training  42.5 %\n",
      "55576.32972913373\n",
      "now training  42.6 %\n",
      "55583.17062236275\n",
      "now training  42.7 %\n",
      "55569.71098263489\n",
      "now training  42.8 %\n",
      "55576.4710833966\n",
      "now training  42.9 %\n",
      "55567.66173912388\n",
      "now training  43.0 %\n",
      "55574.65375636946\n",
      "now training  43.1 %\n",
      "55578.02502079079\n",
      "now training  43.2 %\n",
      "55568.47612988869\n",
      "now training  43.3 %\n",
      "55582.999360482805\n",
      "now training  43.4 %\n",
      "55585.41113114052\n",
      "now training  43.5 %\n",
      "55573.00876908104\n",
      "now training  43.6 %\n",
      "55584.82880507475\n",
      "now training  43.7 %\n",
      "55572.57498105247\n",
      "now training  43.8 %\n",
      "55584.36117697015\n",
      "now training  43.9 %\n",
      "55567.272414993975\n",
      "now training  44.0 %\n",
      "55575.322986500556\n",
      "now training  44.1 %\n",
      "55581.47549476896\n",
      "now training  44.2 %\n",
      "55568.32233548998\n",
      "now training  44.3 %\n",
      "55573.21110817991\n",
      "now training  44.4 %\n",
      "55576.45703572704\n",
      "now training  44.5 %\n",
      "55573.66480491383\n",
      "now training  44.6 %\n",
      "55577.19067464295\n",
      "now training  44.7 %\n",
      "55579.56207448568\n",
      "now training  44.8 %\n",
      "55566.75314063011\n",
      "now training  44.9 %\n",
      "55570.46318009823\n",
      "now training  45.0 %\n",
      "55562.25063239238\n",
      "now training  45.1 %\n",
      "55586.044268552636\n",
      "now training  45.2 %\n",
      "55569.90038206382\n",
      "now training  45.3 %\n",
      "55586.16530382932\n",
      "now training  45.4 %\n",
      "55564.01893090099\n",
      "now training  45.5 %\n",
      "55588.9304059524\n",
      "now training  45.6 %\n",
      "55577.115705175995\n",
      "now training  45.7 %\n",
      "55578.02817568154\n",
      "now training  45.8 %\n",
      "55584.81271769124\n",
      "now training  45.9 %\n",
      "55571.154879510104\n",
      "now training  46.0 %\n",
      "55571.934289944984\n",
      "now training  46.1 %\n",
      "55570.043488863936\n",
      "now training  46.2 %\n",
      "55576.25741840061\n",
      "now training  46.3 %\n",
      "55568.63485458597\n",
      "now training  46.4 %\n",
      "55583.244873986856\n",
      "now training  46.5 %\n",
      "55562.80876578412\n",
      "now training  46.6 %\n",
      "55578.32002379287\n",
      "now training  46.7 %\n",
      "55567.02617290059\n",
      "now training  46.8 %\n",
      "55569.389235998045\n",
      "now training  46.9 %\n",
      "55572.389830926935\n",
      "now training  47.0 %\n",
      "55570.445638620055\n",
      "now training  47.1 %\n",
      "55571.58706469623\n",
      "now training  47.2 %\n",
      "55558.94274598862\n",
      "now training  47.3 %\n",
      "55565.02098739866\n",
      "now training  47.4 %\n",
      "55585.35975219815\n",
      "now training  47.5 %\n",
      "55580.245443527114\n",
      "now training  47.6 %\n",
      "55556.43583971771\n",
      "now training  47.7 %\n",
      "55571.137544196245\n",
      "now training  47.8 %\n",
      "55571.89761304411\n",
      "now training  47.9 %\n",
      "55575.85591000457\n",
      "now training  48.0 %\n",
      "55577.377284096474\n",
      "now training  48.1 %\n",
      "55569.34484153542\n",
      "now training  48.2 %\n",
      "55565.159581764965\n",
      "now training  48.3 %\n",
      "55575.07673079367\n",
      "now training  48.4 %\n",
      "55560.631395789576\n",
      "now training  48.5 %\n",
      "55564.309787184015\n",
      "now training  48.6 %\n",
      "55564.88005799298\n",
      "now training  48.7 %\n",
      "55563.79179292738\n",
      "now training  48.8 %\n",
      "55559.17830831382\n",
      "now training  48.9 %\n",
      "55561.20537055064\n",
      "now training  49.0 %\n",
      "55554.28469190391\n",
      "now training  49.1 %\n",
      "55564.23347519758\n",
      "now training  49.2 %\n",
      "55566.46290437317\n",
      "now training  49.3 %\n",
      "55568.73081976177\n",
      "now training  49.4 %\n",
      "55570.80427245071\n",
      "now training  49.5 %\n",
      "55563.21018521639\n",
      "now training  49.6 %\n",
      "55565.576660164515\n",
      "now training  49.7 %\n",
      "55575.48749794955\n",
      "now training  49.8 %\n",
      "55569.88438383164\n",
      "now training  49.9 %\n",
      "55565.496847828996\n",
      "now training  50.0 %\n",
      "55570.56425658394\n",
      "now training  50.1 %\n",
      "55564.97246945011\n",
      "now training  50.2 %\n",
      "55564.204771799225\n",
      "now training  50.3 %\n",
      "55566.813545792815\n",
      "now training  50.4 %\n",
      "55564.09765009368\n",
      "now training  50.5 %\n",
      "55567.056013305715\n",
      "now training  50.6 %\n",
      "55560.62874933967\n",
      "now training  50.7 %\n",
      "55560.46078240103\n",
      "now training  50.8 %\n",
      "55565.02832485718\n",
      "now training  50.9 %\n",
      "55570.77031796725\n",
      "now training  51.0 %\n",
      "55566.59610594898\n",
      "now training  51.1 %\n",
      "55561.431136599764\n",
      "now training  51.2 %\n",
      "55573.208558732156\n",
      "now training  51.3 %\n",
      "55560.101780747835\n",
      "now training  51.4 %\n",
      "55557.65521044689\n",
      "now training  51.5 %\n",
      "55556.933906381164\n",
      "now training  51.6 %\n",
      "55563.84124857506\n",
      "now training  51.7 %\n",
      "55556.614715891854\n",
      "now training  51.8 %\n",
      "55562.06837509558\n",
      "now training  51.9 %\n",
      "55567.76429262612\n",
      "now training  52.0 %\n",
      "55563.545011490074\n",
      "now training  52.1 %\n",
      "55549.03473327507\n",
      "now training  52.2 %\n",
      "55554.632003921266\n",
      "now training  52.3 %\n",
      "55564.91397833626\n",
      "now training  52.4 %\n",
      "55557.42880613051\n",
      "now training  52.5 %\n",
      "55556.28187224654\n",
      "now training  52.6 %\n",
      "55570.78018341164\n",
      "now training  52.7 %\n",
      "55561.84376761582\n",
      "now training  52.8 %\n",
      "55552.07372272459\n",
      "now training  52.9 %\n",
      "55555.92976627548\n",
      "now training  53.0 %\n",
      "55551.68616345477\n",
      "now training  53.1 %\n",
      "55553.455651452154\n",
      "now training  53.2 %\n",
      "55557.17680984621\n",
      "now training  53.3 %\n",
      "55559.64175364199\n",
      "now training  53.4 %\n",
      "55549.22186027973\n",
      "now training  53.5 %\n",
      "55551.53390481755\n",
      "now training  53.6 %\n",
      "55563.11070700288\n",
      "now training  53.7 %\n",
      "55549.29281236114\n",
      "now training  53.8 %\n",
      "55556.978461249135\n",
      "now training  53.9 %\n",
      "55551.84743467437\n",
      "now training  54.0 %\n",
      "55558.376358931986\n",
      "now training  54.1 %\n",
      "55555.47084647412\n",
      "now training  54.2 %\n",
      "55553.39576173945\n",
      "now training  54.3 %\n",
      "55548.694931471415\n",
      "now training  54.4 %\n",
      "55545.00009650196\n",
      "now training  54.5 %\n",
      "55552.75696197443\n",
      "now training  54.6 %\n",
      "55551.11098038421\n",
      "now training  54.7 %\n",
      "55554.82132699377\n",
      "now training  54.8 %\n",
      "55555.532428043225\n",
      "now training  54.9 %\n",
      "55547.88299996285\n",
      "now training  55.0 %\n",
      "55547.04943086145\n",
      "now training  55.1 %\n",
      "55557.71914238468\n",
      "now training  55.2 %\n",
      "55556.0048940426\n",
      "now training  55.3 %\n",
      "55552.652000123344\n",
      "now training  55.4 %\n",
      "55548.362050261116\n",
      "now training  55.5 %\n",
      "55548.896149879176\n",
      "now training  55.6 %\n",
      "55550.4934500581\n",
      "now training  55.7 %\n",
      "55552.14557811292\n",
      "now training  55.8 %\n",
      "55549.861043312296\n",
      "now training  55.9 %\n",
      "55554.08174723397\n",
      "now training  56.0 %\n",
      "55551.706393753295\n",
      "now training  56.1 %\n",
      "55547.48184310532\n",
      "now training  56.2 %\n",
      "55554.56523108181\n",
      "now training  56.3 %\n",
      "55544.44578190947\n",
      "now training  56.4 %\n",
      "55542.65379877432\n",
      "now training  56.5 %\n",
      "55549.32960078742\n",
      "now training  56.6 %\n",
      "55538.365804345245\n",
      "now training  56.7 %\n",
      "55550.027335445004\n",
      "now training  56.8 %\n",
      "55549.48657435231\n",
      "now training  56.9 %\n",
      "55544.93816433255\n",
      "now training  57.0 %\n",
      "55544.62992395764\n",
      "now training  57.1 %\n",
      "55547.451880623936\n",
      "now training  57.2 %\n",
      "55549.754979387726\n",
      "now training  57.3 %\n",
      "55554.339722777644\n",
      "now training  57.4 %\n",
      "55548.52750785469\n",
      "now training  57.5 %\n",
      "55554.100834697136\n",
      "now training  57.6 %\n",
      "55542.07976534024\n",
      "now training  57.7 %\n",
      "55543.1247204565\n",
      "now training  57.8 %\n",
      "55545.137660877386\n",
      "now training  57.9 %\n",
      "55546.34249988618\n",
      "now training  58.0 %\n",
      "55543.09009443758\n",
      "now training  58.1 %\n",
      "55551.82457834894\n",
      "now training  58.2 %\n",
      "55536.01403217383\n",
      "now training  58.3 %\n",
      "55541.55915895747\n",
      "now training  58.4 %\n",
      "55537.64664812605\n",
      "now training  58.5 %\n",
      "55543.276751992205\n",
      "now training  58.6 %\n",
      "55538.151461622256\n",
      "now training  58.7 %\n",
      "55541.295516194616\n",
      "now training  58.8 %\n",
      "55548.86374865963\n",
      "now training  58.9 %\n",
      "55544.49620171456\n",
      "now training  59.0 %\n",
      "55545.41676178515\n",
      "now training  59.1 %\n",
      "55543.2663391827\n",
      "now training  59.2 %\n",
      "55542.938684600624\n",
      "now training  59.3 %\n",
      "55539.51649410534\n",
      "now training  59.4 %\n",
      "55539.17898053002\n",
      "now training  59.5 %\n",
      "55534.95668821829\n",
      "now training  59.6 %\n",
      "55539.09234202419\n",
      "now training  59.7 %\n",
      "55543.27115215199\n",
      "now training  59.8 %\n",
      "55538.31073513029\n",
      "now training  59.9 %\n",
      "55532.85616108425\n",
      "now training  60.0 %\n",
      "55534.79971973674\n",
      "now training  60.1 %\n",
      "55545.82041527032\n",
      "now training  60.2 %\n",
      "55533.512813225374\n",
      "now training  60.3 %\n",
      "55532.51321161473\n",
      "now training  60.4 %\n",
      "55530.23669797913\n",
      "now training  60.5 %\n",
      "55531.106828821576\n",
      "now training  60.6 %\n",
      "55534.71480564355\n",
      "now training  60.7 %\n",
      "55531.27919780483\n",
      "now training  60.8 %\n",
      "55535.260355158345\n",
      "now training  60.9 %\n",
      "55536.53092751854\n",
      "now training  61.0 %\n",
      "55524.99531518493\n",
      "now training  61.1 %\n",
      "55536.150771156186\n",
      "now training  61.2 %\n",
      "55528.88148447511\n",
      "now training  61.3 %\n",
      "55533.37579952392\n",
      "now training  61.4 %\n",
      "55526.976742378254\n",
      "now training  61.5 %\n",
      "55531.902479070144\n",
      "now training  61.6 %\n",
      "55531.065619481946\n",
      "now training  61.7 %\n",
      "55521.865875607255\n",
      "now training  61.8 %\n",
      "55532.00272044467\n",
      "now training  61.9 %\n",
      "55529.50321788731\n",
      "now training  62.0 %\n",
      "55524.98459829789\n",
      "now training  62.1 %\n",
      "55526.61032289747\n",
      "now training  62.2 %\n",
      "55530.14479013278\n",
      "now training  62.3 %\n",
      "55522.454607508604\n",
      "now training  62.4 %\n",
      "55530.9508160217\n",
      "now training  62.5 %\n",
      "55526.19156023365\n",
      "now training  62.6 %\n",
      "55532.15029692449\n",
      "now training  62.7 %\n",
      "55525.847250306004\n",
      "now training  62.8 %\n",
      "55523.26347434637\n",
      "now training  62.9 %\n",
      "55522.566264106266\n",
      "now training  63.0 %\n",
      "55517.30484349914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now training  63.1 %\n",
      "55522.15885430599\n",
      "now training  63.2 %\n",
      "55519.88649358312\n",
      "now training  63.3 %\n",
      "55519.60961655964\n",
      "now training  63.4 %\n",
      "55522.93792569027\n",
      "now training  63.5 %\n",
      "55521.859493457305\n",
      "now training  63.6 %\n",
      "55518.814055039766\n",
      "now training  63.7 %\n",
      "55518.075654490865\n",
      "now training  63.8 %\n",
      "55520.555386931526\n",
      "now training  63.9 %\n",
      "55514.000671716705\n",
      "now training  64.0 %\n",
      "55511.02776421094\n",
      "now training  64.1 %\n",
      "55513.49721462704\n",
      "now training  64.2 %\n",
      "55516.872062898445\n",
      "now training  64.3 %\n",
      "55514.54354807969\n",
      "now training  64.4 %\n",
      "55519.0914333487\n",
      "now training  64.5 %\n",
      "55514.55607798971\n",
      "now training  64.6 %\n",
      "55517.989349810334\n",
      "now training  64.7 %\n",
      "55506.330475667535\n",
      "now training  64.8 %\n",
      "55511.92547681919\n",
      "now training  64.9 %\n",
      "55518.65407631216\n",
      "now training  65.0 %\n",
      "55516.99378144296\n",
      "now training  65.1 %\n",
      "55515.65224957559\n",
      "now training  65.2 %\n",
      "55517.97673726671\n",
      "now training  65.3 %\n",
      "55515.77470579584\n",
      "now training  65.4 %\n",
      "55516.62229286632\n",
      "now training  65.5 %\n",
      "55512.16713045443\n",
      "now training  65.6 %\n",
      "55511.31757228505\n",
      "now training  65.7 %\n",
      "55510.89802851246\n",
      "now training  65.8 %\n",
      "55507.293735026666\n",
      "now training  65.9 %\n",
      "55513.32522907332\n",
      "now training  66.0 %\n",
      "55521.8524567603\n",
      "now training  66.1 %\n",
      "55516.17825523282\n",
      "now training  66.2 %\n",
      "55512.95098610213\n",
      "now training  66.3 %\n",
      "55512.98276402191\n",
      "now training  66.4 %\n",
      "55516.89558464036\n",
      "now training  66.5 %\n",
      "55507.416450369536\n",
      "now training  66.6 %\n",
      "55512.52783440337\n",
      "now training  66.7 %\n",
      "55503.57928783587\n",
      "now training  66.8 %\n",
      "55522.00280074014\n",
      "now training  66.9 %\n",
      "55515.833866399335\n",
      "now training  67.0 %\n",
      "55509.38333351951\n",
      "now training  67.1 %\n",
      "55507.755997958186\n",
      "now training  67.2 %\n",
      "55506.144353081654\n",
      "now training  67.3 %\n",
      "55511.290001231806\n",
      "now training  67.4 %\n",
      "55505.81411309951\n",
      "now training  67.5 %\n",
      "55506.983438954805\n",
      "now training  67.6 %\n",
      "55500.83740498581\n",
      "now training  67.7 %\n",
      "55506.51210142174\n",
      "now training  67.8 %\n",
      "55505.405073241694\n",
      "now training  67.9 %\n",
      "55510.43992099853\n",
      "now training  68.0 %\n",
      "55508.54759638633\n",
      "now training  68.1 %\n",
      "55504.240652177934\n",
      "now training  68.2 %\n",
      "55503.061041360656\n",
      "now training  68.3 %\n",
      "55504.17048755344\n",
      "now training  68.4 %\n",
      "55506.85292094659\n",
      "now training  68.5 %\n",
      "55504.86342631854\n",
      "now training  68.6 %\n",
      "55508.46680873919\n",
      "now training  68.7 %\n",
      "55502.344698202985\n",
      "now training  68.8 %\n",
      "55502.16850216086\n",
      "now training  68.9 %\n",
      "55501.886183574694\n",
      "now training  69.0 %\n",
      "55501.35184218448\n",
      "now training  69.1 %\n",
      "55499.330713610194\n",
      "now training  69.2 %\n",
      "55495.875093106624\n",
      "now training  69.3 %\n",
      "55497.41799045299\n",
      "now training  69.4 %\n",
      "55502.06938201368\n",
      "now training  69.5 %\n",
      "55497.36968643623\n",
      "now training  69.6 %\n",
      "55493.523488326515\n",
      "now training  69.7 %\n",
      "55502.282758153626\n",
      "now training  69.8 %\n",
      "55506.065444674256\n",
      "now training  69.9 %\n",
      "55502.555559758446\n",
      "now training  70.0 %\n",
      "55494.94700855682\n",
      "now training  70.1 %\n",
      "55497.09739841737\n",
      "now training  70.2 %\n",
      "55497.38988808892\n",
      "now training  70.3 %\n",
      "55494.0333225261\n",
      "now training  70.4 %\n",
      "55495.78179757038\n",
      "now training  70.5 %\n",
      "55492.410812753136\n",
      "now training  70.6 %\n",
      "55491.77363547964\n",
      "now training  70.7 %\n",
      "55487.952116493645\n",
      "now training  70.8 %\n",
      "55498.15317516832\n",
      "now training  70.9 %\n",
      "55490.58771593861\n",
      "now training  71.0 %\n",
      "55498.15746184427\n",
      "now training  71.1 %\n",
      "55495.84157178203\n",
      "now training  71.2 %\n",
      "55494.52198529002\n",
      "now training  71.3 %\n",
      "55489.194697643004\n",
      "now training  71.4 %\n",
      "55490.13437010802\n",
      "now training  71.5 %\n",
      "55487.22594645656\n",
      "now training  71.6 %\n",
      "55487.375799513844\n",
      "now training  71.7 %\n",
      "55496.56482719276\n",
      "now training  71.8 %\n",
      "55491.78729019262\n",
      "now training  71.9 %\n",
      "55489.4246545766\n",
      "now training  72.0 %\n",
      "55493.19596326635\n",
      "now training  72.1 %\n",
      "55491.937700337716\n",
      "now training  72.2 %\n",
      "55489.72177312117\n",
      "now training  72.3 %\n",
      "55487.157820307766\n",
      "now training  72.4 %\n",
      "55484.30240714131\n",
      "now training  72.5 %\n",
      "55485.16644925376\n",
      "now training  72.6 %\n",
      "55487.10432480984\n",
      "now training  72.7 %\n",
      "55484.02930673318\n",
      "now training  72.8 %\n",
      "55487.5411836616\n",
      "now training  72.9 %\n",
      "55490.995975650345\n",
      "now training  73.0 %\n",
      "55484.1331690629\n",
      "now training  73.1 %\n",
      "55482.820578674655\n",
      "now training  73.2 %\n",
      "55483.11889814722\n",
      "now training  73.3 %\n",
      "55482.48276982808\n",
      "now training  73.4 %\n",
      "55485.43526935007\n",
      "now training  73.5 %\n",
      "55483.864720970305\n",
      "now training  73.6 %\n",
      "55484.24668152893\n",
      "now training  73.7 %\n",
      "55482.174893222706\n",
      "now training  73.8 %\n",
      "55478.59313680044\n",
      "now training  73.9 %\n",
      "55478.16749108677\n",
      "now training  74.0 %\n",
      "55478.02319231766\n",
      "now training  74.1 %\n",
      "55482.229811807294\n",
      "now training  74.2 %\n",
      "55481.665984769934\n",
      "now training  74.3 %\n",
      "55480.96115474993\n",
      "now training  74.4 %\n",
      "55474.655198722525\n",
      "now training  74.5 %\n",
      "55478.26184864719\n",
      "now training  74.6 %\n",
      "55479.38434642659\n",
      "now training  74.7 %\n",
      "55478.767995555056\n",
      "now training  74.8 %\n",
      "55476.52879613485\n",
      "now training  74.9 %\n",
      "55482.16640535915\n",
      "now training  75.0 %\n",
      "55477.98879653236\n",
      "now training  75.1 %\n",
      "55472.65790173231\n",
      "now training  75.2 %\n",
      "55478.105733317774\n",
      "now training  75.3 %\n",
      "55475.71646887473\n",
      "now training  75.4 %\n",
      "55469.91207870004\n",
      "now training  75.5 %\n",
      "55476.22391694912\n",
      "now training  75.6 %\n",
      "55478.6609700031\n",
      "now training  75.7 %\n",
      "55476.19060696418\n",
      "now training  75.8 %\n",
      "55477.97083051695\n",
      "now training  75.9 %\n",
      "55476.62816878153\n",
      "now training  76.0 %\n",
      "55473.257070605905\n",
      "now training  76.1 %\n",
      "55473.65565445581\n",
      "now training  76.2 %\n",
      "55475.52994874258\n",
      "now training  76.3 %\n",
      "55472.33578087549\n",
      "now training  76.4 %\n",
      "55473.75909866548\n",
      "now training  76.5 %\n",
      "55468.33326927762\n",
      "now training  76.6 %\n",
      "55476.21844490062\n",
      "now training  76.7 %\n",
      "55470.84175575765\n",
      "now training  76.8 %\n",
      "55471.518137481995\n",
      "now training  76.9 %\n",
      "55470.04509906094\n",
      "now training  77.0 %\n",
      "55470.04946808906\n",
      "now training  77.1 %\n",
      "55468.44681189843\n",
      "now training  77.2 %\n",
      "55468.56465043119\n",
      "now training  77.3 %\n",
      "55467.44281047952\n",
      "now training  77.4 %\n",
      "55465.973004132786\n",
      "now training  77.5 %\n",
      "55468.73259505732\n",
      "now training  77.6 %\n",
      "55465.728188236404\n",
      "now training  77.7 %\n",
      "55471.76322708703\n",
      "now training  77.8 %\n",
      "55467.652491020744\n",
      "now training  77.9 %\n",
      "55468.199655753895\n",
      "now training  78.0 %\n",
      "55466.56947399146\n",
      "now training  78.1 %\n",
      "55466.41453827045\n",
      "now training  78.2 %\n",
      "55466.30723131089\n",
      "now training  78.3 %\n",
      "55465.723079979296\n",
      "now training  78.4 %\n",
      "55469.07775958511\n",
      "now training  78.5 %\n",
      "55465.23975367349\n",
      "now training  78.6 %\n",
      "55461.20633004143\n",
      "now training  78.7 %\n",
      "55466.8962690288\n",
      "now training  78.8 %\n",
      "55460.01679463105\n",
      "now training  78.9 %\n",
      "55467.80247711507\n",
      "now training  79.0 %\n",
      "55460.96913353837\n",
      "now training  79.1 %\n",
      "55464.85759330982\n",
      "now training  79.2 %\n",
      "55462.55437210103\n",
      "now training  79.3 %\n",
      "55460.74400391206\n",
      "now training  79.4 %\n",
      "55462.08978168391\n",
      "now training  79.5 %\n",
      "55459.02504432002\n",
      "now training  79.6 %\n",
      "55460.46141321321\n",
      "now training  79.7 %\n",
      "55461.102351572714\n",
      "now training  79.8 %\n",
      "55460.00639944263\n",
      "now training  79.9 %\n",
      "55456.87066920843\n",
      "now training  80.0 %\n",
      "55460.00795880365\n",
      "now training  80.1 %\n",
      "55456.13706441903\n",
      "now training  80.2 %\n",
      "55460.76818362728\n",
      "now training  80.3 %\n",
      "55464.2946480133\n",
      "now training  80.4 %\n",
      "55459.31402781014\n",
      "now training  80.5 %\n",
      "55457.50886498373\n",
      "now training  80.6 %\n",
      "55457.71527385402\n",
      "now training  80.7 %\n",
      "55458.35839204851\n",
      "now training  80.8 %\n",
      "55459.2258414265\n",
      "now training  80.9 %\n",
      "55455.7528893203\n",
      "now training  81.0 %\n",
      "55457.36213167044\n",
      "now training  81.1 %\n",
      "55453.38276823332\n",
      "now training  81.2 %\n",
      "55454.76277811565\n",
      "now training  81.3 %\n",
      "55454.87454233999\n",
      "now training  81.4 %\n",
      "55454.36650986705\n",
      "now training  81.5 %\n",
      "55449.88008857324\n",
      "now training  81.6 %\n",
      "55450.494376551425\n",
      "now training  81.7 %\n",
      "55446.62031367977\n",
      "now training  81.8 %\n",
      "55453.5770149856\n",
      "now training  81.9 %\n",
      "55454.274602765916\n",
      "now training  82.0 %\n",
      "55452.9194302352\n",
      "now training  82.1 %\n",
      "55452.59916124382\n",
      "now training  82.2 %\n",
      "55453.73710819993\n",
      "now training  82.3 %\n",
      "55451.57841492002\n",
      "now training  82.4 %\n",
      "55448.25301123702\n",
      "now training  82.5 %\n",
      "55449.835250293094\n",
      "now training  82.6 %\n",
      "55451.83894596872\n",
      "now training  82.7 %\n",
      "55450.827943909906\n",
      "now training  82.8 %\n",
      "55452.341719215605\n",
      "now training  82.9 %\n",
      "55454.26770938316\n",
      "now training  83.0 %\n",
      "55453.74707851371\n",
      "now training  83.1 %\n",
      "55450.10137035238\n",
      "now training  83.2 %\n",
      "55450.13735631403\n",
      "now training  83.3 %\n",
      "55447.50372884037\n",
      "now training  83.4 %\n",
      "55448.252939016835\n",
      "now training  83.5 %\n",
      "55452.43953061093\n",
      "now training  83.6 %\n",
      "55445.202488426614\n",
      "now training  83.7 %\n",
      "55450.63524307741\n",
      "now training  83.8 %\n",
      "55446.29039213956\n",
      "now training  83.9 %\n",
      "55444.71130375861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now training  84.0 %\n",
      "55444.22482079164\n",
      "now training  84.1 %\n",
      "55445.70343590676\n",
      "now training  84.2 %\n",
      "55447.217081274386\n",
      "now training  84.3 %\n",
      "55445.955142719904\n",
      "now training  84.4 %\n",
      "55445.892547653726\n",
      "now training  84.5 %\n",
      "55446.40782095148\n",
      "now training  84.6 %\n",
      "55446.06735944912\n",
      "now training  84.7 %\n",
      "55446.27436437836\n",
      "now training  84.8 %\n",
      "55445.90536710818\n",
      "now training  84.9 %\n",
      "55444.83329388467\n",
      "now training  85.0 %\n",
      "55441.6097582246\n",
      "now training  85.1 %\n",
      "55442.71960787567\n",
      "now training  85.2 %\n",
      "55445.23959552971\n",
      "now training  85.3 %\n",
      "55442.27443956127\n",
      "now training  85.4 %\n",
      "55442.47034562244\n",
      "now training  85.5 %\n",
      "55443.0072019919\n",
      "now training  85.6 %\n",
      "55442.81872601565\n",
      "now training  85.7 %\n",
      "55441.428546941475\n",
      "now training  85.8 %\n",
      "55441.08192684305\n",
      "now training  85.9 %\n",
      "55443.55671884189\n",
      "now training  86.0 %\n",
      "55440.452022497986\n",
      "now training  86.1 %\n",
      "55442.1075357147\n",
      "now training  86.2 %\n",
      "55442.22392081153\n",
      "now training  86.3 %\n",
      "55440.39781572447\n",
      "now training  86.4 %\n",
      "55439.51511002265\n",
      "now training  86.5 %\n",
      "55439.32398997671\n",
      "now training  86.6 %\n",
      "55437.433186044975\n",
      "now training  86.7 %\n",
      "55438.43522383487\n",
      "now training  86.8 %\n",
      "55436.03707669045\n",
      "now training  86.9 %\n",
      "55435.643789274196\n",
      "now training  87.0 %\n",
      "55439.104581488726\n",
      "now training  87.1 %\n",
      "55435.39372957818\n",
      "now training  87.2 %\n",
      "55436.86583088453\n",
      "now training  87.3 %\n",
      "55436.909258548825\n",
      "now training  87.4 %\n",
      "55438.54446654646\n",
      "now training  87.5 %\n",
      "55436.05140388719\n",
      "now training  87.6 %\n",
      "55435.63820358475\n",
      "now training  87.7 %\n",
      "55436.31554448846\n",
      "now training  87.8 %\n",
      "55434.81300672947\n",
      "now training  87.9 %\n",
      "55439.629481506156\n",
      "now training  88.0 %\n",
      "55437.838602568256\n",
      "now training  88.1 %\n",
      "55436.033879880466\n",
      "now training  88.2 %\n",
      "55435.39168155499\n",
      "now training  88.3 %\n",
      "55434.872306341174\n",
      "now training  88.4 %\n",
      "55431.0279962352\n",
      "now training  88.5 %\n",
      "55432.43280421411\n",
      "now training  88.6 %\n",
      "55432.619777023036\n",
      "now training  88.7 %\n",
      "55435.78677262615\n",
      "now training  88.8 %\n",
      "55432.681387525845\n",
      "now training  88.9 %\n",
      "55436.87110818921\n",
      "now training  89.0 %\n",
      "55433.475161165945\n",
      "now training  89.1 %\n",
      "55433.45494976882\n",
      "now training  89.2 %\n",
      "55433.93342856476\n",
      "now training  89.3 %\n",
      "55433.72351727406\n",
      "now training  89.4 %\n",
      "55435.01364243789\n",
      "now training  89.5 %\n",
      "55434.39002520227\n",
      "now training  89.6 %\n",
      "55431.530852621116\n",
      "now training  89.7 %\n",
      "55433.09906484386\n",
      "now training  89.8 %\n",
      "55434.03564908242\n",
      "now training  89.9 %\n",
      "55434.870392430894\n",
      "now training  90.0 %\n",
      "55432.5327022577\n",
      "now training  90.1 %\n",
      "55434.24079194927\n",
      "now training  90.2 %\n",
      "55433.263587290625\n",
      "now training  90.3 %\n",
      "55428.008258865666\n",
      "now training  90.4 %\n",
      "55429.90883855203\n",
      "now training  90.5 %\n",
      "55431.51910476056\n",
      "now training  90.6 %\n",
      "55431.9816337699\n",
      "now training  90.7 %\n",
      "55429.15954035276\n",
      "now training  90.8 %\n",
      "55429.36292251207\n",
      "now training  90.9 %\n",
      "55430.90365265851\n",
      "now training  91.0 %\n",
      "55427.18685507231\n",
      "now training  91.1 %\n",
      "55430.496150983694\n",
      "now training  91.2 %\n",
      "55429.9852510145\n",
      "now training  91.3 %\n",
      "55430.64146362247\n",
      "now training  91.4 %\n",
      "55430.38872204553\n",
      "now training  91.5 %\n",
      "55431.319840502256\n",
      "now training  91.6 %\n",
      "55427.64393001664\n",
      "now training  91.7 %\n",
      "55429.08243252203\n",
      "now training  91.8 %\n",
      "55429.62153054823\n",
      "now training  91.9 %\n",
      "55426.80969271691\n",
      "now training  92.0 %\n",
      "55426.248797852306\n",
      "now training  92.1 %\n",
      "55428.73542737499\n",
      "now training  92.2 %\n",
      "55425.469296518626\n",
      "now training  92.3 %\n",
      "55427.21637791467\n",
      "now training  92.4 %\n",
      "55426.41816859108\n",
      "now training  92.5 %\n",
      "55426.742319132994\n",
      "now training  92.6 %\n",
      "55426.60365354373\n",
      "now training  92.7 %\n",
      "55424.178056503035\n",
      "now training  92.8 %\n",
      "55426.38468405507\n",
      "now training  92.9 %\n",
      "55423.6541692337\n",
      "now training  93.0 %\n",
      "55425.34952461312\n",
      "now training  93.1 %\n",
      "55424.63336046834\n",
      "now training  93.2 %\n",
      "55424.71044670053\n",
      "now training  93.3 %\n",
      "55424.42836761386\n",
      "now training  93.4 %\n",
      "55421.38011329879\n",
      "now training  93.5 %\n",
      "55421.82665848233\n",
      "now training  93.6 %\n",
      "55426.79704042498\n",
      "now training  93.7 %\n",
      "55423.42192542457\n",
      "now training  93.8 %\n",
      "55421.991619575405\n",
      "now training  93.9 %\n",
      "55423.01798245295\n",
      "now training  94.0 %\n",
      "55421.42010227971\n",
      "now training  94.1 %\n",
      "55422.14069182454\n",
      "now training  94.2 %\n",
      "55420.40242855246\n",
      "now training  94.3 %\n",
      "55422.4175435232\n",
      "now training  94.4 %\n",
      "55420.59135231744\n",
      "now training  94.5 %\n",
      "55421.11413241979\n",
      "now training  94.6 %\n",
      "55421.92151371573\n",
      "now training  94.7 %\n",
      "55418.88233307979\n",
      "now training  94.8 %\n",
      "55424.64483188528\n",
      "now training  94.9 %\n",
      "55421.92662768258\n",
      "now training  95.0 %\n",
      "55419.8058463485\n",
      "now training  95.1 %\n",
      "55422.74770953551\n",
      "now training  95.2 %\n",
      "55421.05680615299\n",
      "now training  95.3 %\n",
      "55420.71321980636\n",
      "now training  95.4 %\n",
      "55420.277569345504\n",
      "now training  95.5 %\n",
      "55419.07874234549\n",
      "now training  95.6 %\n",
      "55418.4942289996\n",
      "now training  95.7 %\n",
      "55420.14812375947\n",
      "now training  95.8 %\n",
      "55421.46531615132\n",
      "now training  95.9 %\n",
      "55419.96254388389\n",
      "now training  96.0 %\n",
      "55418.26487066972\n",
      "now training  96.1 %\n",
      "55420.75952252226\n",
      "now training  96.2 %\n",
      "55421.89418964939\n",
      "now training  96.3 %\n",
      "55419.686737957156\n",
      "now training  96.4 %\n",
      "55417.89471814949\n",
      "now training  96.5 %\n",
      "55417.752314838246\n",
      "now training  96.6 %\n",
      "55416.4527282989\n",
      "now training  96.7 %\n",
      "55416.887930643854\n",
      "now training  96.8 %\n",
      "55416.54595781583\n",
      "now training  96.9 %\n",
      "55416.27599367755\n",
      "now training  97.0 %\n",
      "55419.53141950473\n",
      "now training  97.1 %\n",
      "55416.01095571567\n",
      "now training  97.2 %\n",
      "55415.92936297209\n",
      "now training  97.3 %\n",
      "55417.22680947991\n",
      "now training  97.4 %\n",
      "55418.317743287276\n",
      "now training  97.5 %\n",
      "55415.95035337311\n",
      "now training  97.6 %\n",
      "55415.77164429194\n",
      "now training  97.7 %\n",
      "55416.46557758856\n",
      "now training  97.8 %\n",
      "55416.33442523424\n",
      "now training  97.9 %\n",
      "55416.11289673511\n",
      "now training  98.0 %\n",
      "55416.47038449078\n",
      "now training  98.1 %\n",
      "55416.29699095103\n",
      "now training  98.2 %\n",
      "55414.496583774046\n",
      "now training  98.3 %\n",
      "55416.54420089441\n",
      "now training  98.4 %\n",
      "55414.1066804838\n",
      "now training  98.5 %\n",
      "55413.927109875425\n",
      "now training  98.6 %\n",
      "55414.411758317365\n",
      "now training  98.7 %\n",
      "55415.263420722986\n",
      "now training  98.8 %\n",
      "55414.07130572197\n",
      "now training  98.9 %\n",
      "55413.79015500222\n",
      "now training  99.0 %\n",
      "55414.76761873378\n",
      "now training  99.1 %\n",
      "55414.33778611191\n",
      "now training  99.2 %\n",
      "55412.60222800633\n",
      "now training  99.3 %\n",
      "55411.74725741139\n",
      "now training  99.4 %\n",
      "55413.17485010669\n",
      "now training  99.5 %\n",
      "55412.52102347655\n",
      "now training  99.6 %\n",
      "55412.70507641678\n",
      "now training  99.7 %\n",
      "55412.49426000335\n",
      "now training  99.8 %\n",
      "55408.997605345736\n",
      "now training  99.9 %\n",
      "55411.537739220774\n"
     ]
    }
   ],
   "source": [
    "epochtimes = 200000\n",
    "mini_batch = 128\n",
    "bestloss1 = 1e30 #Mini Batch Loss\n",
    "preloss = 1e30   #decay the learning rate\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(epochtimes):\n",
    "    X_train_random = []\n",
    "    Y_train_random = []\n",
    "    for i in range(mini_batch):\n",
    "        rindex = random.randint(0,len(X_train)-1)\n",
    "        X_train_random.append(X_train[rindex,:])\n",
    "        Y_train_random.append(Y_train[rindex,:])\n",
    "    X_train_random = np.array(X_train_random)\n",
    "    Y_train_random = np.array(Y_train_random)\n",
    "    \n",
    "        \n",
    "    input_hidden = np.dot(X_train_random, weight_hidden) \n",
    "    output_hidden = ReLU(input_hidden)\n",
    "    \n",
    "    input_hidden2 = np.dot(output_hidden, weight_hidden2) \n",
    "    output_hidden2 = ReLU(input_hidden2)\n",
    "    input_hidden3 = np.dot(output_hidden2, weight_hidden3) \n",
    "    output_hidden3 = ReLU(input_hidden3)\n",
    "    input_hidden4 = np.dot(output_hidden3, weight_hidden4) \n",
    "    output_hidden4 = ReLU(input_hidden4)\n",
    "    input_hidden5 = np.dot(output_hidden4, weight_hidden5) \n",
    "    output_hidden5 = ReLU(input_hidden5)\n",
    "    input_op = np.dot(output_hidden5, weight_output)\n",
    "    output_op = ReLU(input_op)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #==========================================\n",
    "    \n",
    "    derror_douto = output_op - Y_train_random\n",
    "    douto_dino = ReLU_der(input_op)\n",
    "    dino_dwo = output_hidden5      \n",
    "    derror_dwo = np.dot(dino_dwo.T, derror_douto * douto_dino)\n",
    "    \n",
    "    #==========================================\n",
    "    \n",
    "    derror_dino = derror_douto * douto_dino\n",
    "    dino_douth5 = weight_output\n",
    "    derror_douth5 = np.dot(derror_dino, dino_douth5.T)\n",
    "    douth5_dinh5 = ReLU_der(input_hidden5)\n",
    "    dinh5_dwh5 = output_hidden4\n",
    "    derror_dwh5 = np.dot(dinh5_dwh5.T, douth5_dinh5 * derror_douth5)\n",
    "    \n",
    "    #==========================================\n",
    "    \n",
    "    derror_dinh5 = derror_douth5 * douth5_dinh5\n",
    "    dinh5_douth4 = weight_hidden5\n",
    "    derror_douth4 = np.dot(derror_dinh5, dinh5_douth4.T)\n",
    "    douth4_dinh4 = ReLU_der(input_hidden4)\n",
    "    dinh4_dwh4 = output_hidden3\n",
    "    derror_dwh4 = np.dot(dinh4_dwh4.T, douth4_dinh4 * derror_douth4)\n",
    "    \n",
    "    #==========================================\n",
    "    \n",
    "    derror_dinh4 = derror_douth4 * douth4_dinh4\n",
    "    dinh4_douth3 = weight_hidden4\n",
    "    derror_douth3 = np.dot(derror_dinh4, dinh4_douth3.T)\n",
    "    douth3_dinh3 = ReLU_der(input_hidden3)\n",
    "    dinh3_dwh3 = output_hidden2\n",
    "    derror_dwh3 = np.dot(dinh3_dwh3.T, douth3_dinh3 * derror_douth3)\n",
    "    \n",
    "    #==========================================\n",
    "    \n",
    "    derror_dinh3 = derror_douth3 * douth3_dinh3\n",
    "    dinh3_douth2 = weight_hidden3\n",
    "    derror_douth2 = np.dot(derror_dinh3, dinh3_douth2.T)\n",
    "    douth2_dinh2 = ReLU_der(input_hidden2)\n",
    "    dinh2_dwh2 = output_hidden\n",
    "    derror_dwh2 = np.dot(dinh2_dwh2.T, douth2_dinh2 * derror_douth2)\n",
    "    \n",
    "    #==========================================\n",
    "    \n",
    "    derror_dinh2 = derror_douth2 * douth2_dinh2\n",
    "    dinh2_douth = weight_hidden2\n",
    "    derror_douth = np.dot(derror_dinh2, dinh2_douth.T)\n",
    "    douth_dinh = ReLU_der(input_hidden)\n",
    "    dinh_dwh = X_train_random\n",
    "    derror_dwh = np.dot(dinh_dwh.T, douth_dinh * derror_douth)\n",
    "    \n",
    "    #==========================================\n",
    "       \n",
    "    \n",
    "    \n",
    "    weight_hidden -= limit(lr * derror_dwh)\n",
    "    weight_hidden2 -= limit(lr * derror_dwh2)\n",
    "    weight_hidden3 -= limit(lr * derror_dwh3)\n",
    "    weight_hidden4 -= limit(lr * derror_dwh4)\n",
    "    weight_hidden5 -= limit(lr * derror_dwh5)\n",
    "    weight_output -= limit(lr * derror_dwo)\n",
    "    \n",
    "    \n",
    "    error_out = ((1 / 2) * (np.power((output_op - Y_train_random), 2)))\n",
    "    #print(error_out.sum())\n",
    "    \n",
    "        \n",
    "        \n",
    "    #calulate error \n",
    "    if epoch % 200 == 0 : \n",
    "        input_hidden = np.dot(X_train, weight_hidden) \n",
    "        output_hidden = ReLU(input_hidden)\n",
    "        input_hidden2 = np.dot(input_hidden, weight_hidden2) \n",
    "        output_hidden2 = ReLU(input_hidden2)\n",
    "        input_hidden3 = np.dot(output_hidden2, weight_hidden3) \n",
    "        output_hidden3 = ReLU(input_hidden3)\n",
    "        input_hidden4 = np.dot(output_hidden3, weight_hidden4) \n",
    "        output_hidden4 = ReLU(input_hidden4)\n",
    "        input_hidden5 = np.dot(output_hidden4, weight_hidden5) \n",
    "        output_hidden5 = ReLU(input_hidden5)\n",
    "        input_op = np.dot(output_hidden5, weight_output)\n",
    "        output_op = ReLU(input_op)\n",
    "        error_out = ((1 / 2) * (np.power((output_op - Y_train), 2)))\n",
    "        \n",
    "        if epoch == 0 : \n",
    "            preloss = error_out.sum()     \n",
    "            \n",
    "        if error_out.sum() < preloss :\n",
    "            mbwh1 = np.copy(weight_hidden)     #collect the best minibatch weight vector\n",
    "            mbwh2 = np.copy(weight_hidden2)\n",
    "            mbwh3 = np.copy(weight_hidden3)\n",
    "            mbwh4 = np.copy(weight_hidden4)\n",
    "            mbwh5 = np.copy(weight_hidden5)\n",
    "            mbwo  = np.copy(weight_output)\n",
    "            lr *= error_out.sum() / preloss\n",
    "            preloss = error_out.sum()  \n",
    "        \n",
    "        print('now training ',epoch*100/epochtimes,'%')\n",
    "        print(error_out.sum())\n",
    "        #print(error_out)\n",
    "        #print('\\n',lr * derror_dwh,'\\n', lr * derror_dwo,'\\n')\n",
    "        \n",
    "       \n",
    "    #print(derror_wh, derror_wo)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.86911682e-06  6.43288850e-07  4.15102538e-07 ...  8.71373892e-07\n",
      "  -5.96282256e-07  9.79096224e-08]\n",
      " [ 1.28232005e-06  7.25169479e-07  1.77898205e-07 ... -3.52333347e-09\n",
      "  -3.29764985e-07  1.74583502e-09]\n",
      " [ 7.16353394e-07 -1.21247187e-06 -2.77419759e-07 ...  9.48543113e-07\n",
      "  -2.05538823e-06 -1.08951977e-09]\n",
      " ...\n",
      " [-2.54493315e-06 -9.11280595e-07  8.35945419e-07 ... -6.85888336e-07\n",
      "   4.10643961e-06 -1.09636679e-07]\n",
      " [ 1.73339669e-06  7.47552492e-07 -7.96398760e-07 ...  7.71127251e-07\n",
      "  -3.57154713e-06  8.95189814e-08]\n",
      " [ 4.46604974e-06  1.99081801e-06  6.79185249e-07 ...  4.32474899e-07\n",
      "  -3.44846243e-06 -8.66141711e-08]]\n",
      "[[ 5.64294133e-07  1.23721804e-06 -2.32000255e-09 ...  3.64772943e-07\n",
      "  -1.97543867e-06  9.05378217e-07]\n",
      " [ 2.84306740e-08 -1.75539672e-07 -5.46669633e-10 ... -1.00901222e-07\n",
      "   3.69011068e-07 -8.02408483e-07]\n",
      " [ 1.05697175e-07  1.78116371e-07  8.56563918e-11 ... -3.65930529e-08\n",
      "  -2.68824068e-07  3.44644425e-07]\n",
      " ...\n",
      " [ 1.95356691e-07 -7.97407459e-08  3.78709331e-08 ... -9.04456410e-08\n",
      "  -2.50562422e-07 -4.52090029e-07]\n",
      " [ 5.17051899e-07  9.71587046e-07 -1.11218147e-09 ...  2.71426363e-07\n",
      "  -1.25945840e-06  1.08060850e-06]\n",
      " [-5.90947820e-10 -3.01104011e-09 -2.54583441e-10 ... -4.29571755e-09\n",
      "  -3.41381294e-09 -1.69261015e-09]]\n",
      "[[ 1.53572871e-06 -1.33881344e-07 -3.21772855e-07 ...  4.81855086e-07\n",
      "  -2.49342905e-07 -1.55730614e-07]\n",
      " [ 9.70888290e-07 -1.63953036e-07 -1.59610952e-07 ...  4.53620571e-07\n",
      "  -4.06412693e-07 -6.72346860e-08]\n",
      " [-6.19100536e-08 -3.13007003e-08  7.09543964e-08 ... -3.15716252e-08\n",
      "   6.79980176e-09  2.42173114e-09]\n",
      " ...\n",
      " [ 2.83980772e-07 -1.30561997e-07 -6.57050288e-08 ...  3.86139584e-08\n",
      "   1.21508991e-07 -4.23646373e-08]\n",
      " [ 2.35517078e-07 -1.02258148e-06 -6.79591991e-08 ...  2.48631659e-07\n",
      "  -4.88388926e-07 -8.74565601e-08]\n",
      " [ 4.15379016e-07 -3.88491413e-07  4.06818199e-08 ...  1.07812471e-07\n",
      "   1.43092938e-08 -1.08456269e-08]]\n",
      "[[-3.58859763e-08 -2.46143844e-08  6.84393417e-08 ... -3.45871705e-10\n",
      "  -3.99179318e-08 -4.75069944e-07]\n",
      " [-1.58550004e-07 -8.77833335e-07  1.10057600e-06 ... -3.02322187e-09\n",
      "   3.65555268e-07 -3.08760333e-07]\n",
      " [ 8.89671292e-08  3.16336455e-07 -3.16869158e-07 ...  1.37994729e-09\n",
      "   5.37166391e-08 -2.97793058e-08]\n",
      " ...\n",
      " [-2.61901153e-07 -8.00411562e-07  9.77048437e-07 ... -2.98523745e-09\n",
      "   1.16399620e-07 -8.45640926e-07]\n",
      " [ 1.20912885e-07  6.43104492e-07 -7.28919712e-07 ...  1.65047875e-09\n",
      "  -3.28980571e-09  2.82003207e-07]\n",
      " [-1.19690797e-08 -4.01916160e-08  4.63625271e-08 ... -1.42389068e-10\n",
      "  -2.90112926e-09 -3.54589272e-08]]\n",
      "[[ 7.89822221e-07  1.86943887e-07 -6.38018685e-08  6.56270353e-08\n",
      "   1.89122585e-07 -2.23251530e-08  1.34451901e-06 -3.40932320e-07]\n",
      " [-8.72454791e-08  3.45955095e-07 -6.55064192e-08  2.94870062e-07\n",
      "   4.82457727e-07 -1.48938754e-08 -1.48518492e-07  4.58114408e-07]\n",
      " [ 2.96183034e-06  7.40211742e-07 -1.73098560e-07  4.48762458e-07\n",
      "   1.79477579e-07 -4.73151650e-08  5.04194119e-06 -4.84984120e-07]\n",
      " [-9.56743340e-07  1.27635435e-07  1.28887582e-07  4.02561608e-07\n",
      "   4.37626215e-07 -4.51690424e-09 -1.62866981e-06  6.29020899e-07]\n",
      " [-4.87277004e-07 -4.03253801e-08  1.12868916e-07  1.22656098e-07\n",
      "   1.39868172e-07 -1.77092997e-10 -8.29494507e-07  2.32338973e-07]\n",
      " [ 1.64132507e-07 -3.23353871e-08 -1.66254563e-08  1.81447259e-07\n",
      "  -1.32323638e-09 -2.40541200e-09  2.79403731e-07 -8.03124386e-08]\n",
      " [-2.31028937e-08 -5.51790677e-09  1.65485488e-09 -2.90397035e-10\n",
      "  -9.21616066e-10  3.20518340e-10 -3.93281917e-08  4.91801658e-09]\n",
      " [ 3.23381266e-07  2.65819521e-07 -2.52728355e-08  1.30244716e-07\n",
      "   4.47003947e-07 -1.69233121e-08  5.50493830e-07  3.41401154e-07]\n",
      " [-1.31493760e-07 -3.26869739e-08 -1.83378109e-10  2.40764644e-08\n",
      "  -2.53142572e-09  8.61545584e-10 -2.23842601e-07  9.61322988e-08]\n",
      " [ 1.40380559e-06  3.46382819e-07 -1.19496406e-07 -3.78563209e-08\n",
      "  -9.74722158e-09 -2.96694053e-08  2.38970651e-06 -2.92531369e-07]\n",
      " [-5.88074489e-07  1.18003744e-09  1.06132721e-07  1.12298476e-07\n",
      "   2.54018802e-07  3.58013384e-09 -1.00108266e-06  2.83968194e-07]\n",
      " [ 1.85965576e-06  4.45519530e-07 -1.15114962e-08 -7.59216994e-08\n",
      "  -1.32095365e-08 -1.11532285e-08  3.16570293e-06 -2.01637248e-07]\n",
      " [-2.45466239e-08 -6.96874159e-09  2.61141280e-09 -3.52221941e-09\n",
      "  -3.12971137e-09  4.80306517e-10 -4.17858621e-08  5.87997830e-09]\n",
      " [-1.44269102e-07  9.33165626e-10  7.27969399e-10  3.08011183e-08\n",
      "  -9.26597096e-10  9.73066486e-10 -2.45590141e-07  6.88030792e-08]\n",
      " [-1.33616166e-08 -4.45269875e-09  8.38391407e-10 -3.32394020e-09\n",
      "  -2.98523233e-09  3.45450876e-10 -2.27455585e-08  2.07358901e-09]\n",
      " [ 3.66140252e-07  1.65568379e-07  7.74465951e-08 -3.29427396e-08\n",
      "   1.77999442e-07 -2.17670505e-09  6.23282703e-07  1.32745318e-07]\n",
      " [ 3.80291447e-07  3.78658834e-08 -9.27025584e-08  3.51662421e-07\n",
      "   5.88245699e-08 -1.19540750e-08  6.47372366e-07 -1.82640649e-07]\n",
      " [-8.70054035e-07  7.72867633e-08  8.68787493e-08  1.78923165e-07\n",
      "   3.54536420e-07 -4.37132487e-09 -1.48109810e-06  4.98282322e-07]\n",
      " [ 5.39757549e-07  3.10759344e-07 -2.70621338e-07  2.00457711e-07\n",
      "   1.13452028e-07 -2.07563455e-08  9.18832448e-07  2.13442893e-07]\n",
      " [-6.51221461e-07 -7.63362398e-08  8.19006760e-08  2.09077536e-07\n",
      "   1.30739463e-07  4.02510834e-09 -1.10857812e-06  3.10611810e-07]\n",
      " [ 4.58140088e-08  3.26177733e-08 -5.70995535e-09  9.06781963e-09\n",
      "  -3.12958880e-09 -8.23849077e-11  7.79894565e-08  4.66027528e-08]\n",
      " [ 9.36492338e-07  4.09971539e-07 -3.36066641e-08  1.15762351e-07\n",
      "   3.29778793e-07 -5.55719616e-09  1.59419641e-06  1.03036584e-07]\n",
      " [ 2.21341956e-06  4.77211822e-07 -1.23760516e-07  2.00688059e-08\n",
      "  -1.35134518e-08 -2.23424406e-08  3.76791712e-06 -5.00040094e-07]\n",
      " [ 1.22885369e-07  1.87611615e-08 -6.35666683e-10 -3.49522679e-09\n",
      "  -3.50289174e-09 -7.07915508e-10  2.09188486e-07 -6.28471642e-08]\n",
      " [-1.69959419e-07 -3.45061392e-09 -4.98045993e-09  3.14646885e-08\n",
      "   1.64130589e-10  1.12636125e-09 -2.89322918e-07  7.97940344e-08]\n",
      " [ 2.55274796e-07  1.36028250e-07  3.15709915e-08  4.54587598e-08\n",
      "   8.41591323e-08 -1.45887779e-09  4.34555786e-07  9.80690226e-08]\n",
      " [ 1.36124922e-06  4.65652081e-07 -2.39978881e-07  2.23726438e-07\n",
      "   2.15549025e-07 -1.85280654e-08  2.31726255e-06 -2.24227254e-08]\n",
      " [ 5.27646659e-07  1.66230436e-07 -3.81254070e-08  1.74170777e-09\n",
      "   1.11131441e-08 -3.04904020e-09  8.98216010e-07  9.34051352e-08]\n",
      " [ 2.59791675e-06  7.69380377e-07 -2.29539903e-07  2.36480482e-07\n",
      "   2.10252247e-07 -2.10125407e-08  4.42244896e-06 -3.45894771e-07]\n",
      " [ 1.40626347e-06  3.19551670e-07 -1.98515614e-07  1.31836803e-07\n",
      "   3.46911902e-08 -3.53811091e-08  2.39389057e-06 -4.15638267e-07]\n",
      " [ 2.24765416e-06  5.72774227e-07 -5.62253663e-08 -2.12962487e-07\n",
      "   1.40142120e-07 -2.08390224e-08  3.82619488e-06 -2.29573172e-07]\n",
      " [ 2.43784921e-08 -6.71815808e-09  8.94490481e-10 -4.13840314e-10\n",
      "  -3.46555269e-09  1.08393542e-10  4.14996504e-08 -2.14683941e-08]\n",
      " [ 2.78280888e-07  1.94657216e-07 -2.31361111e-07  3.38323328e-07\n",
      "   1.25248213e-07 -2.19463132e-08  4.73719191e-07 -4.33900946e-08]\n",
      " [-2.10584390e-08 -3.96581734e-09  6.54868131e-10 -5.36588773e-10\n",
      "  -8.37157019e-10  3.28872551e-10 -3.58479046e-08  5.08853587e-09]\n",
      " [-6.35292276e-08 -6.99408749e-08 -4.61254261e-09  7.79783515e-08\n",
      "  -1.20143969e-09 -1.35390140e-08 -1.08146178e-07  7.78333984e-08]\n",
      " [ 3.52186351e-07  9.46598346e-08 -3.02935630e-10  1.82357414e-08\n",
      "  -3.26530648e-09 -2.01140074e-09  5.99528895e-07 -1.67319795e-07]\n",
      " [ 4.17275604e-08 -1.16109500e-09 -1.72548853e-10 -2.66941145e-09\n",
      "  -1.82861109e-09 -1.64425408e-10  7.10330714e-08 -2.50766743e-08]\n",
      " [-5.90881938e-07  9.87550983e-08  5.29392175e-08  1.78735779e-07\n",
      "   3.50996845e-07 -1.90206461e-08 -1.00586180e-06  4.05693674e-07]\n",
      " [-5.43184522e-09 -3.05892066e-09  6.21545863e-10 -6.00752136e-09\n",
      "  -4.35636256e-09  3.24147864e-10 -9.24666204e-09 -8.90721372e-10]\n",
      " [-1.10701788e-07 -5.31718324e-09  2.03217926e-08  1.87301126e-08\n",
      "   4.59707492e-08  6.82220129e-10 -1.88448305e-07  5.06170991e-08]\n",
      " [ 7.16133351e-07  2.39486097e-07 -2.45796329e-07  3.55676106e-07\n",
      "   9.06879642e-08 -2.18075405e-08  1.21907801e-06 -9.75338393e-08]\n",
      " [ 2.08483512e-07  1.75580685e-07  4.99298478e-08  5.69272303e-07\n",
      "   2.98529867e-07 -3.14250242e-08  3.54902707e-07  2.65730465e-08]\n",
      " [-3.32787615e-07 -3.91346138e-09  5.56396442e-08  6.50343664e-08\n",
      "   9.90060142e-08  2.03204572e-09 -5.66506313e-07  1.55658477e-07]\n",
      " [ 5.81913101e-08  8.70707473e-09  1.19830808e-08 -1.63752094e-08\n",
      "   2.50748765e-08 -2.34382510e-10  9.90594093e-08 -5.38721055e-09]\n",
      " [-6.94951896e-07  1.56631237e-07  2.40636434e-07  2.98551880e-07\n",
      "   4.54837439e-07  4.20353852e-09 -1.18302070e-06  3.93829531e-07]\n",
      " [ 2.14980914e-06  3.61582914e-07 -2.21864071e-07  1.18686462e-07\n",
      "  -1.38268542e-08 -3.95157830e-08  3.65963274e-06 -1.05430862e-06]\n",
      " [ 5.25123732e-08 -2.26505420e-09 -2.64223143e-08 -1.11899767e-08\n",
      "  -4.49584917e-09 -1.75625000e-10  8.93921215e-08 -2.86736139e-08]\n",
      " [-1.23586353e-06  2.20043845e-07  1.03102369e-07  8.55201779e-07\n",
      "   6.41657118e-07 -2.05886890e-08 -2.10381776e-06  1.15691825e-06]\n",
      " [-5.87767550e-07  6.82098937e-08  1.81678692e-07  1.87508748e-07\n",
      "   3.86298285e-07 -2.73893231e-09 -1.00056016e-06  3.63450980e-07]\n",
      " [-1.22867927e-06 -1.54619635e-07  1.19735903e-08  3.25719111e-07\n",
      "   1.61802290e-07 -5.61766513e-09 -2.09158794e-06  5.85374212e-07]\n",
      " [-2.11749898e-08 -7.02754591e-09  2.56793160e-09 -1.09692263e-09\n",
      "  -1.43527541e-09  2.40650017e-10 -3.60463095e-08  5.03470573e-10]\n",
      " [ 2.21106117e-07  6.96519408e-08 -1.67685962e-09  1.50541718e-07\n",
      "  -1.60612848e-09 -7.68493839e-09  3.76390242e-07 -1.10844932e-07]\n",
      " [-6.73781512e-08 -1.90260581e-09 -5.87504526e-09  2.47191079e-08\n",
      "  -4.77002181e-10  5.22785647e-10 -1.14698223e-07  2.92459509e-08]\n",
      " [ 6.42142946e-07  1.31436845e-07 -8.29093388e-08  5.32029136e-08\n",
      "   3.45929074e-08 -3.73472606e-09  1.09312371e-06 -1.50090450e-07]\n",
      " [ 4.82934015e-07  1.88039776e-07 -2.38964832e-08  1.73637403e-07\n",
      "   2.13059427e-07 -1.65999327e-08  8.22101413e-07 -2.42254921e-07]\n",
      " [ 5.68810548e-07  2.21373385e-07 -2.31629976e-07  1.55436101e-07\n",
      "   4.26659751e-08 -1.85162553e-08  9.68289540e-07  6.53148967e-08]\n",
      " [-6.42515179e-08 -2.78409010e-09  9.76890005e-08  1.03967345e-07\n",
      "   1.93884950e-07  5.64588165e-10 -1.09375737e-07  3.00890474e-08]\n",
      " [ 1.32327111e-06  4.88243898e-07 -1.54951211e-07  2.09882242e-07\n",
      "   2.07491442e-07 -2.43985967e-08  2.25261219e-06 -1.02887063e-07]\n",
      " [-1.65558830e-08  1.09463699e-07 -1.97029405e-07  1.40843035e-07\n",
      "  -1.20442335e-09 -1.45301687e-08 -2.81831770e-08  5.20064190e-07]\n",
      " [-2.34075496e-07 -3.32399912e-08  1.54283758e-08  4.53410251e-08\n",
      "  -1.75621370e-09  1.48424981e-09 -3.98468094e-07  1.01922647e-07]\n",
      " [ 6.38096414e-07  1.39291422e-07 -6.29564113e-09 -1.92157542e-08\n",
      "  -5.27176294e-09 -8.10990614e-09  1.08623528e-06 -2.83956740e-07]\n",
      " [-2.12613913e-09 -2.50393288e-09  3.30216972e-10 -3.75933368e-09\n",
      "  -2.34385012e-09  1.31068790e-10 -3.61933914e-09 -1.47491315e-09]\n",
      " [ 4.24342484e-07  8.49123735e-08 -2.75328317e-08 -5.16266869e-08\n",
      "  -5.15823641e-09 -2.50016922e-09  7.22360704e-07 -3.75101542e-08]\n",
      " [ 5.07714793e-07  5.41067354e-08 -5.34322059e-08 -1.28819141e-08\n",
      "  -3.75656761e-09 -3.02670046e-09  8.64285877e-07 -2.29234965e-07]]\n",
      "[[ 3.62646112e-06]\n",
      " [ 1.69909837e-06]\n",
      " [-1.34265683e-07]\n",
      " [-1.12222190e-06]\n",
      " [-8.05144029e-08]\n",
      " [ 2.14467341e-08]\n",
      " [ 3.08998273e-06]\n",
      " [-1.01980411e-06]]\n",
      "Elapsed (with compilation) = 200.1892385482788\n"
     ]
    }
   ],
   "source": [
    "#print(weight_hidden)\n",
    "print(lr * derror_dwh)\n",
    "print(lr * derror_dwh2)\n",
    "print(lr * derror_dwh3)\n",
    "print(lr * derror_dwh4)\n",
    "print(lr * derror_dwh5)\n",
    "print(lr * derror_dwo)\n",
    "print(\"Elapsed (with compilation) = %s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0218172973052488e-05\n"
     ]
    }
   ],
   "source": [
    "single_point = np.array(X_train)\n",
    "result1 = np.dot(single_point, weight_hidden)\n",
    "result2 = ReLU(result1)\n",
    "result3 = np.dot(result2, weight_hidden2)\n",
    "result4 = ReLU(result3)\n",
    "result5 = np.dot(result4, weight_hidden3)\n",
    "result6 = ReLU(result5)\n",
    "result7 = np.dot(result6, weight_hidden4)\n",
    "result8 = ReLU(result7)\n",
    "result9 = np.dot(result8, weight_hidden5)\n",
    "result10 = ReLU(result9)\n",
    "result11 = np.dot(result10, weight_output)\n",
    "result12 = ReLU(result11)\n",
    "#print(result12)\n",
    "#print(Y_train_random)\n",
    "error_out = ((1/len(Y_train)) * (np.power((result12 - Y_train), 2)))\n",
    "#print(error_out)\n",
    "print(error_out.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32.13019721]\n",
      " [36.98304639]\n",
      " [32.13389434]\n",
      " [27.11138245]\n",
      " [13.72066162]\n",
      " [16.56793144]\n",
      " [21.03726633]\n",
      " [15.46069275]\n",
      " [29.06649501]\n",
      " [11.36826686]\n",
      " [34.1042784 ]\n",
      " [29.31932746]\n",
      " [29.73784315]\n",
      " [27.60910403]\n",
      " [29.44723199]\n",
      " [13.32020899]\n",
      " [34.01244006]\n",
      " [14.84013686]\n",
      " [26.02907149]\n",
      " [14.46334995]\n",
      " [27.83565056]\n",
      " [30.1848088 ]\n",
      " [28.71482709]\n",
      " [10.22741394]\n",
      " [34.94870274]\n",
      " [12.87040886]\n",
      " [32.93389551]\n",
      " [34.81344884]\n",
      " [26.69211823]\n",
      " [31.07394477]\n",
      " [14.79589129]\n",
      " [13.23779766]\n",
      " [41.85806882]\n",
      " [13.53684666]\n",
      " [17.41482654]\n",
      " [18.67257255]\n",
      " [33.06230753]\n",
      " [15.43576651]\n",
      " [34.27375567]\n",
      " [27.66225949]\n",
      " [12.03651016]\n",
      " [15.00169167]\n",
      " [29.38885784]\n",
      " [34.69649096]\n",
      " [17.36495127]\n",
      " [33.67687821]\n",
      " [14.02345117]\n",
      " [42.31797633]\n",
      " [29.24246357]\n",
      " [31.2552352 ]\n",
      " [10.04788538]\n",
      " [10.13612086]\n",
      " [15.7006402 ]\n",
      " [34.557012  ]\n",
      " [30.24445234]\n",
      " [16.91657383]\n",
      " [13.90193115]\n",
      " [31.9811879 ]\n",
      " [33.40290996]\n",
      " [15.68817071]\n",
      " [36.84955473]\n",
      " [13.60340612]\n",
      " [43.07260931]\n",
      " [42.67994558]\n",
      " [17.55177462]\n",
      " [17.29614331]\n",
      " [27.31181416]\n",
      " [33.21514277]\n",
      " [13.55847716]\n",
      " [33.64778631]\n",
      " [24.81825664]\n",
      " [25.26197903]\n",
      " [14.36627853]\n",
      " [ 9.04014661]\n",
      " [11.59672279]\n",
      " [12.08719218]\n",
      " [37.90898985]\n",
      " [28.09769431]\n",
      " [30.25162732]\n",
      " [13.59770497]\n",
      " [10.50042938]\n",
      " [ 7.719365  ]\n",
      " [12.55729951]\n",
      " [10.52183888]\n",
      " [12.31911573]\n",
      " [ 9.26985166]\n",
      " [ 9.92727045]\n",
      " [42.77094499]\n",
      " [33.90899902]\n",
      " [17.12760771]\n",
      " [13.60779427]\n",
      " [40.64290021]\n",
      " [16.54560088]\n",
      " [22.62481839]\n",
      " [30.38125569]\n",
      " [28.07948822]\n",
      " [31.0324712 ]\n",
      " [32.42967125]\n",
      " [35.91808963]\n",
      " [16.87578361]\n",
      " [37.06917636]\n",
      " [32.09913658]\n",
      " [23.53149583]\n",
      " [12.46746006]\n",
      " [34.17691112]\n",
      " [12.83761265]\n",
      " [12.63350362]\n",
      " [ 7.32713298]\n",
      " [28.72646723]\n",
      " [12.93083122]\n",
      " [12.23587028]\n",
      " [12.27506022]\n",
      " [21.03439406]\n",
      " [ 8.20260869]\n",
      " [11.66573347]\n",
      " [29.30589716]\n",
      " [11.76304652]\n",
      " [36.90080176]\n",
      " [10.82122729]\n",
      " [14.96045858]\n",
      " [33.19354453]\n",
      " [39.56911568]\n",
      " [26.64046814]\n",
      " [12.91087778]\n",
      " [13.57611435]\n",
      " [30.49950331]\n",
      " [33.89445259]\n",
      " [35.28802532]\n",
      " [ 8.59646494]\n",
      " [31.93163708]\n",
      " [15.53082392]\n",
      " [11.1975691 ]\n",
      " [37.82261145]\n",
      " [13.78184412]\n",
      " [13.82133429]\n",
      " [15.3712375 ]\n",
      " [25.58127424]\n",
      " [36.41160615]\n",
      " [15.56247366]\n",
      " [29.24355548]\n",
      " [14.41301817]\n",
      " [11.60334082]\n",
      " [13.06121736]\n",
      " [30.91470067]\n",
      " [38.49351984]\n",
      " [16.33691788]\n",
      " [42.39195685]\n",
      " [12.26688044]\n",
      " [38.75972901]\n",
      " [28.82732868]\n",
      " [ 8.8515628 ]\n",
      " [19.45897958]\n",
      " [11.77997938]\n",
      " [10.82044745]\n",
      " [29.79089612]\n",
      " [16.07355887]\n",
      " [24.28837111]\n",
      " [ 9.70120715]\n",
      " [33.22607146]\n",
      " [11.92816004]\n",
      " [30.83523394]\n",
      " [13.57847807]\n",
      " [14.86827225]\n",
      " [33.37874101]\n",
      " [41.2375568 ]\n",
      " [10.88636511]\n",
      " [30.21977761]\n",
      " [15.68656019]\n",
      " [29.65054342]\n",
      " [13.83622667]\n",
      " [40.91014602]\n",
      " [30.10507169]\n",
      " [20.14354902]\n",
      " [36.34070462]\n",
      " [18.41802561]\n",
      " [ 9.9810321 ]\n",
      " [30.17135669]\n",
      " [ 9.7982998 ]\n",
      " [29.73903024]\n",
      " [32.0674677 ]\n",
      " [28.53091664]\n",
      " [ 7.88659408]\n",
      " [32.57202819]\n",
      " [ 9.7141554 ]\n",
      " [24.50675887]\n",
      " [12.2732416 ]\n",
      " [14.29795316]\n",
      " [31.87439001]\n",
      " [37.10461566]\n",
      " [13.28121202]\n",
      " [17.64896603]\n",
      " [33.34520343]]\n",
      "[[32.21]\n",
      " [35.99]\n",
      " [32.67]\n",
      " [25.43]\n",
      " [14.08]\n",
      " [13.02]\n",
      " [19.06]\n",
      " [14.58]\n",
      " [29.79]\n",
      " [14.41]\n",
      " [37.24]\n",
      " [31.29]\n",
      " [28.56]\n",
      " [28.15]\n",
      " [24.6 ]\n",
      " [12.47]\n",
      " [32.26]\n",
      " [12.41]\n",
      " [23.84]\n",
      " [12.87]\n",
      " [28.67]\n",
      " [25.7 ]\n",
      " [26.84]\n",
      " [12.43]\n",
      " [35.73]\n",
      " [11.42]\n",
      " [32.31]\n",
      " [33.27]\n",
      " [24.4 ]\n",
      " [32.06]\n",
      " [16.44]\n",
      " [11.43]\n",
      " [41.3 ]\n",
      " [12.29]\n",
      " [15.23]\n",
      " [16.44]\n",
      " [32.94]\n",
      " [16.76]\n",
      " [36.06]\n",
      " [24.96]\n",
      " [11.16]\n",
      " [14.54]\n",
      " [25.37]\n",
      " [36.47]\n",
      " [15.55]\n",
      " [36.7 ]\n",
      " [12.86]\n",
      " [39.86]\n",
      " [28.17]\n",
      " [28.95]\n",
      " [11.18]\n",
      " [10.77]\n",
      " [16.86]\n",
      " [35.48]\n",
      " [28.61]\n",
      " [15.36]\n",
      " [15.41]\n",
      " [28.63]\n",
      " [29.67]\n",
      " [16.66]\n",
      " [32.73]\n",
      " [15.16]\n",
      " [42.08]\n",
      " [39.86]\n",
      " [19.12]\n",
      " [14.54]\n",
      " [28.09]\n",
      " [32.82]\n",
      " [13.  ]\n",
      " [35.94]\n",
      " [26.37]\n",
      " [22.89]\n",
      " [11.34]\n",
      " [10.32]\n",
      " [12.95]\n",
      " [14.62]\n",
      " [38.82]\n",
      " [27.27]\n",
      " [28.6 ]\n",
      " [14.21]\n",
      " [10.7 ]\n",
      " [ 6.77]\n",
      " [13.97]\n",
      " [10.14]\n",
      " [12.32]\n",
      " [10.46]\n",
      " [11.32]\n",
      " [40.78]\n",
      " [36.43]\n",
      " [17.69]\n",
      " [15.21]\n",
      " [42.11]\n",
      " [18.48]\n",
      " [25.36]\n",
      " [32.31]\n",
      " [27.02]\n",
      " [33.12]\n",
      " [29.49]\n",
      " [36.97]\n",
      " [19.36]\n",
      " [36.26]\n",
      " [32.46]\n",
      " [24.77]\n",
      " [12.97]\n",
      " [37.26]\n",
      " [12.33]\n",
      " [14.1 ]\n",
      " [ 6.01]\n",
      " [28.52]\n",
      " [12.12]\n",
      " [12.71]\n",
      " [10.36]\n",
      " [27.03]\n",
      " [ 6.79]\n",
      " [14.39]\n",
      " [29.22]\n",
      " [14.12]\n",
      " [38.57]\n",
      " [11.22]\n",
      " [15.34]\n",
      " [32.15]\n",
      " [36.45]\n",
      " [28.37]\n",
      " [10.64]\n",
      " [13.94]\n",
      " [26.97]\n",
      " [28.91]\n",
      " [34.29]\n",
      " [10.39]\n",
      " [32.67]\n",
      " [16.69]\n",
      " [ 8.5 ]\n",
      " [36.06]\n",
      " [13.04]\n",
      " [14.5 ]\n",
      " [14.53]\n",
      " [24.03]\n",
      " [35.69]\n",
      " [12.63]\n",
      " [28.31]\n",
      " [18.31]\n",
      " [12.25]\n",
      " [12.18]\n",
      " [28.05]\n",
      " [41.32]\n",
      " [12.97]\n",
      " [39.31]\n",
      " [11.69]\n",
      " [36.64]\n",
      " [24.17]\n",
      " [ 8.49]\n",
      " [15.34]\n",
      " [11.45]\n",
      " [12.73]\n",
      " [36.71]\n",
      " [13.  ]\n",
      " [24.23]\n",
      " [10.45]\n",
      " [32.85]\n",
      " [10.75]\n",
      " [28.15]\n",
      " [11.22]\n",
      " [12.82]\n",
      " [35.65]\n",
      " [42.74]\n",
      " [10.47]\n",
      " [28.62]\n",
      " [14.61]\n",
      " [29.01]\n",
      " [10.07]\n",
      " [39.81]\n",
      " [29.83]\n",
      " [17.41]\n",
      " [36.57]\n",
      " [17.88]\n",
      " [10.66]\n",
      " [32.23]\n",
      " [ 7.1 ]\n",
      " [28.67]\n",
      " [32.21]\n",
      " [32.05]\n",
      " [10.85]\n",
      " [35.96]\n",
      " [11.2 ]\n",
      " [23.75]\n",
      " [12.67]\n",
      " [16.83]\n",
      " [29.53]\n",
      " [41.09]\n",
      " [14.75]\n",
      " [19.34]\n",
      " [32.72]]\n",
      "192\n",
      "2.0820986858418777\n"
     ]
    }
   ],
   "source": [
    "single_point = np.array(X_test)\n",
    "result1 = np.dot(single_point, weight_hidden)\n",
    "result2 = ReLU(result1)\n",
    "result3 = np.dot(result2, weight_hidden2)\n",
    "result4 = ReLU(result3)\n",
    "result5 = np.dot(result4, weight_hidden3)\n",
    "result6 = ReLU(result5)\n",
    "result7 = np.dot(result6, weight_hidden4)\n",
    "result8 = ReLU(result7)\n",
    "result9 = np.dot(result8, weight_hidden5)\n",
    "result10 = ReLU(result9)\n",
    "result11 = np.dot(result10, weight_output)\n",
    "result12 = ReLU(result11)\n",
    "print(result12)\n",
    "print(Y_test)\n",
    "print(len(X_test))\n",
    "error_out = ((1/len(X_test)) * (np.power((result12 - Y_test), 2)))\n",
    "print(math.sqrt(error_out.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestloss1 =  1e+30\n",
      "6.730482153168909\n"
     ]
    }
   ],
   "source": [
    "single_point = np.array(X_train)\n",
    "result1 = np.dot(single_point, mbwh1)\n",
    "result2 = ReLU(result1)\n",
    "result3 = np.dot(result2, mbwh2)\n",
    "result4 = ReLU(result3)\n",
    "result5 = np.dot(result4, mbwh3)\n",
    "result6 = ReLU(result5)\n",
    "result7 = np.dot(result6, mbwh4)\n",
    "result8 = ReLU(result7)\n",
    "result9 = np.dot(result8, mbwh5)\n",
    "result10 = ReLU(result9)\n",
    "result11 = np.dot(result10, mbwo)\n",
    "result12 = ReLU(result11)\n",
    "print(\"bestloss1 = \", bestloss1)\n",
    "#print(result12)\n",
    "#print(Y_train_random)\n",
    "error_out = ((1/len(Y_train)) * (np.power((result12 - Y_train), 2)))\n",
    "print(error_out.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
